{"cells":[{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1719,"status":"ok","timestamp":1675539442426,"user":{"displayName":"Jihed Dachraoui","userId":"07546071455318038160"},"user_tz":-60},"id":"7IU3as4W0cM7","outputId":"19154967-c9f7-46a1-d1fd-fd82ce9fad7c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["# basics\n","import sys\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","import numpy as np \n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import seaborn as sns\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import auc\n","import cv2\n","import pickle \n","from PIL import Image\n","import shutil\n","# Keras Libraries\n","import keras\n","import tensorflow as tf\n","from keras import backend as K\n","from keras import metrics\n","from tensorflow.keras.utils import load_img, img_to_array\n","from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n","from keras.regularizers import l2\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, InputLayer, Activation\n","from keras.utils import  load_img\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.metrics import AUC\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping\n","from sklearn.metrics import classification_report, confusion_matrix\n","import keras.backend\n","import os\n","import random\n","import time\n","import datetime\n","from tensorflow.python.framework import ops\n","import inspect\n","import gc"]},{"cell_type":"code","source":["accuracies=[]"],"metadata":{"id":"oJzAKLnD7UQj","executionInfo":{"status":"ok","timestamp":1675539442426,"user_tz":-60,"elapsed":3,"user":{"displayName":"Jihed Dachraoui","userId":"07546071455318038160"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["batch_size = 14\n","target_size= (300,600)\n","# Define the path to the 5 folds\n","folders = [\"/content/gdrive/MyDrive/Dataset/data_fold4\",\"/content/gdrive/MyDrive/Dataset/data_fold3\", \"/content/gdrive/MyDrive/Dataset/data_fold2\",\"/content/gdrive/MyDrive/Dataset/data_fold1\",\"/content/gdrive/MyDrive/Dataset/data_fold0\"]\n","model_name='mobilenet'"],"metadata":{"id":"VIxzE43Zf9QG","executionInfo":{"status":"ok","timestamp":1675539442426,"user_tz":-60,"elapsed":2,"user":{"displayName":"Jihed Dachraoui","userId":"07546071455318038160"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","# Initialize a list to store the accuracy scores\n","\n","\n","# Iterate over the 5 folds\n","for fold in folders:\n","\n","    fold_name = fold.split(\"/\")[-1]\n","    model_path=\"/content/gdrive/MyDrive/Dataset/output/models/Modelmax+min__{}_{}.h5\".format(model_name,fold_name)\n","    train_path = fold + r\"/train\"\n","   \n","    test_path = fold + r\"/test\"\n","\n","    # Define the data generator\n","    datagen = ImageDataGenerator( rescale=1.0/255.0,\n","                                   shear_range = 0.02,\n","                                   zoom_range = 0.02, rotation_range=10,\n","                                  fill_mode='nearest',\n","                                  \n","                                  \n","                                  width_shift_range=0.1,\n","                                  height_shift_range=0.1)\n","\n","    # Define the generator that will read images from the fold directory and their labels\n","    \n","    test_generator = datagen.flow_from_directory(directory = test_path, \n","                                                    color_mode=\"rgb\",\n","                                                        target_size = target_size, # image height , image width\n","                                                        class_mode=\"categorical\",\n","                                                        batch_size=batch_size,\n","                                                        shuffle=True,\n","                                                        seed=42)\n","\n","    test_generator.reset()\n","\n","    model=tf.keras.models.load_model(model_path)\n","    model.compile(optimizer=keras.optimizers.Adam(learning_rate=.1),loss='categorical_crossentropy',metrics=['accuracy'])\n","    accuracy = model.evaluate(test_generator)\n","    accuracies.append(accuracy)\n","    print(accuracy)\n","    print(\"Accuracy: {:.4f}%\".format(accuracy[1] * 100))\n","    print(\"Loss: \",accuracy[0])\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BDGcDM-J4DZ3","executionInfo":{"status":"ok","timestamp":1675539539178,"user_tz":-60,"elapsed":96754,"user":{"displayName":"Jihed Dachraoui","userId":"07546071455318038160"}},"outputId":"28c6eaa0-ae51-41bd-e2c6-007690282d45"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 56 images belonging to 4 classes.\n","4/4 [==============================] - 11s 2s/step - loss: 1.1458 - accuracy: 0.5714\n","[1.1457890272140503, 0.5714285969734192]\n","Accuracy: 57.1429%\n","Loss:  1.1457890272140503\n","Found 54 images belonging to 4 classes.\n","4/4 [==============================] - 10s 2s/step - loss: 0.9506 - accuracy: 0.5741\n","[0.9505614638328552, 0.5740740895271301]\n","Accuracy: 57.4074%\n","Loss:  0.9505614638328552\n","Found 84 images belonging to 4 classes.\n","6/6 [==============================] - 15s 2s/step - loss: 0.9771 - accuracy: 0.5952\n","[0.9770656824111938, 0.5952380895614624]\n","Accuracy: 59.5238%\n","Loss:  0.9770656824111938\n","Found 66 images belonging to 4 classes.\n","5/5 [==============================] - 12s 2s/step - loss: 0.7670 - accuracy: 0.6818\n","[0.7669796347618103, 0.6818181872367859]\n","Accuracy: 68.1818%\n","Loss:  0.7669796347618103\n","Found 98 images belonging to 4 classes.\n","7/7 [==============================] - 18s 2s/step - loss: 0.7712 - accuracy: 0.7449\n","[0.7712336778640747, 0.7448979616165161]\n","Accuracy: 74.4898%\n","Loss:  0.7712336778640747\n"]}]},{"cell_type":"code","source":["df = pd.DataFrame(accuracies)\n","df.to_csv('/content/gdrive/MyDrive/Dataset/output/eval/accuracy_{}.csv'.format(model_name), index=False)"],"metadata":{"id":"Ub_gbpXM_Opm","executionInfo":{"status":"ok","timestamp":1675539539508,"user_tz":-60,"elapsed":342,"user":{"displayName":"Jihed Dachraoui","userId":"07546071455318038160"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["accuracies=np.array(accuracies)[:,1]\n","# Print the mean accuracy\n","print(\"Mean Accuracy: {:.2f}%\".format(accuracies.mean() * 100))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DEkHO-Qr6rq2","executionInfo":{"status":"ok","timestamp":1675539539508,"user_tz":-60,"elapsed":6,"user":{"displayName":"Jihed Dachraoui","userId":"07546071455318038160"}},"outputId":"fb598039-1bf9-460f-badf-0dbfc00e23bf"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Accuracy: 63.35%\n"]}]},{"cell_type":"code","source":["R=[]\n","import tensorflow as tf\n","def recall(y_true, y_pred):\n","    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1)))\n","    recall = true_positives / (possible_positives + tf.keras.backend.epsilon())\n","    return recall\n","\n","def precision(y_pred, y_true):\n","    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n","    predicted_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n","    return precision\n","\n","def f1_score(y_true, y_pred):\n","    p = precision(y_true, y_pred)\n","    r = recall(y_true, y_pred)\n","    f1_score= 2 * ((p * r) / (p + r + tf.keras.backend.epsilon()))\n","    return f1_score\n","\n","\n"],"metadata":{"id":"PkTfAQtyopF4","executionInfo":{"status":"ok","timestamp":1675539539509,"user_tz":-60,"elapsed":4,"user":{"displayName":"Jihed Dachraoui","userId":"07546071455318038160"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","execution_count":28,"metadata":{"id":"urSqLWBtya6f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675539626308,"user_tz":-60,"elapsed":86803,"user":{"displayName":"Jihed Dachraoui","userId":"07546071455318038160"}},"outputId":"b7c9b22b-8a16-4a83-a1cb-f0942f106ddd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 56 images belonging to 4 classes.\n","4/4 [==============================] - 11s 2s/step - loss: 1.1318 - accuracy: 0.5714 - precision: 0.4643 - recall: 0.4643 - f1_score: 0.4643\n","              Value\n","Loss       1.131809\n","Accuracy   0.571429\n","Precision  0.464286\n","Recall     0.464286\n","F1-Score   0.464286\n","Found 54 images belonging to 4 classes.\n","4/4 [==============================] - 11s 2s/step - loss: 0.9760 - accuracy: 0.5926 - precision: 0.4464 - recall: 0.4464 - f1_score: 0.4464\n","              Value\n","Loss       0.976033\n","Accuracy   0.592593\n","Precision  0.446429\n","Recall     0.446429\n","F1-Score   0.446429\n","Found 84 images belonging to 4 classes.\n","6/6 [==============================] - 15s 2s/step - loss: 0.9677 - accuracy: 0.6071 - precision: 0.4405 - recall: 0.4405 - f1_score: 0.4405\n","              Value\n","Loss       0.967660\n","Accuracy   0.607143\n","Precision  0.440476\n","Recall     0.440476\n","F1-Score   0.440476\n","Found 66 images belonging to 4 classes.\n","5/5 [==============================] - 12s 2s/step - loss: 0.7789 - accuracy: 0.6970 - precision: 0.5971 - recall: 0.5971 - f1_score: 0.5971\n","              Value\n","Loss       0.778884\n","Accuracy   0.696970\n","Precision  0.597143\n","Recall     0.597143\n","F1-Score   0.597143\n","Found 98 images belonging to 4 classes.\n","7/7 [==============================] - 17s 2s/step - loss: 0.7677 - accuracy: 0.7551 - precision: 0.5714 - recall: 0.5714 - f1_score: 0.5714\n","              Value\n","Loss       0.767694\n","Accuracy   0.755102\n","Precision  0.571429\n","Recall     0.571429\n","F1-Score   0.571429\n"]}],"source":["\n","for fold in folders:\n","\n","    fold_name = fold.split(\"/\")[-1]\n","    model_path=\"/content/gdrive/MyDrive/Dataset/output/models/Modelmax+min__{}_{}.h5\".format(model_name,fold_name)\n","    \n","   \n","    test_path = fold + r\"/test\"\n","\n","    # Define the data generator\n","   \n","        \n","\n","    datagen = ImageDataGenerator( rescale=1.0/255.0,\n","                                      shear_range = 0.02,\n","                                      zoom_range = 0.02, rotation_range=10,\n","                                      fill_mode='nearest',\n","                                      horizontal_flip=True,\n","                                      \n","                                      width_shift_range=0.1,\n","                                      height_shift_range=0.1)\n","\n","        \n","    test_generator = datagen.flow_from_directory(directory = test_path , \n","                                                        color_mode=\"rgb\",\n","                                                            target_size = target_size, # image height , image width\n","                                                            class_mode=\"categorical\",\n","                                                            batch_size=batch_size,\n","                                                            shuffle=True,\n","                                                                seed=42)\n","    # load the saved model\n","    custom_objects = {'precision': precision,'recall': recall,'f1_score': f1_score}\n","    model = tf.keras.models.load_model(model_path,custom_objects=custom_objects)\n","\n","    # compile the model with appropriate metrics\n","\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy',precision,recall,f1_score])\n","\n","    # evaluate the model on the test data\n","    results = model.evaluate(test_generator,verbose=1)\n","\n","    # create a dictionary to store the evaluation results\n","    metrics = ['Loss', 'Accuracy', 'Precision', 'Recall', 'F1-Score']\n","    results_dict = {metrics[i]: results[i] for i in range(len(metrics))}\n","    R.append(results_dict)\n","    # convert the dictionary to a pandas dataframe\n","    results_df = pd.DataFrame.from_dict(results_dict, orient='index', columns=['Value'])\n","\n","    # print the evaluation results table\n","    print(results_df)"]},{"cell_type":"code","source":["df = pd.DataFrame(R)\n","df.to_csv('/content/gdrive/MyDrive/Dataset/output/eval/stats_{}.csv'.format(model_name), index=False)"],"metadata":{"id":"4bFJZzz_o4af","executionInfo":{"status":"ok","timestamp":1675539626308,"user_tz":-60,"elapsed":12,"user":{"displayName":"Jihed Dachraoui","userId":"07546071455318038160"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["# method2 eval"],"metadata":{"id":"NwfeHdBLM6SZ"}},{"cell_type":"code","source":["R1=[]"],"metadata":{"id":"1n1kr1gwNEgF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the path to the 5 folds\n","folders = [\"/content/gdrive/MyDrive/Dataset/data_fold4\",\"/content/gdrive/MyDrive/Dataset/data_fold3\", \"/content/gdrive/MyDrive/Dataset/data_fold2\",\"/content/gdrive/MyDrive/Dataset/data_fold1\",\"/content/gdrive/MyDrive/Dataset/data_fold0\"]\n","\n","# Initialize a list to store the accuracy scores\n","\n","\n","# Iterate over the 5 folds\n","for fold in folders:\n","\n","    fold_name = fold.split(\"/\")[-1]\n","    fold_name = fold_name.split(\"_\")[-1]\n","    model_path=\"/content/gdrive/MyDrive/Dataset/output/models/model_tuned_{}_{}.h5\".format(model_name,fold_name)\n","    train_path = fold + r\"/train\"\n","   \n","    test_path = fold + r\"/test\"\n","\n","    # Define the data generator\n","    datagen = ImageDataGenerator( rescale=1.0/255.0,\n","                                   shear_range = 0.02,\n","                                   zoom_range = 0.02, rotation_range=10,\n","                                  fill_mode='nearest',\n","                                  \n","                                  \n","                                  width_shift_range=0.1,\n","                                  height_shift_range=0.1)\n","\n","    # Define the generator that will read images from the fold directory and their labels\n","    \n","    test_generator = datagen.flow_from_directory(directory = test_path, \n","                                                    color_mode=\"rgb\",\n","                                                        target_size = (240,240), # image height , image width\n","                                                        class_mode=\"categorical\",\n","                                                        batch_size=batch_size,\n","                                                        shuffle=True,\n","                                                        seed=42)\n","\n","    test_generator.reset()\n","\n","    custom_objects = {'precision': precision,'recall': recall,'f1_score': f1_score}\n","    model = tf.keras.models.load_model(model_path,custom_objects=custom_objects)\n","\n","    # compile the model with appropriate metrics\n","\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy',precision,recall,f1_score])\n","\n","    # evaluate the model on the test data\n","    results = model.evaluate(test_generator,verbose=1)\n","\n","    # create a dictionary to store the evaluation results\n","    metrics = ['Loss', 'Accuracy', 'Precision', 'Recall', 'F1-Score']\n","    results_dict = {metrics[i]: results[i] for i in range(len(metrics))}\n","    R.append(results_dict)\n","    # convert the dictionary to a pandas dataframe\n","    results_df = pd.DataFrame.from_dict(results_dict, orient='index', columns=['Value'])\n","\n","    # print the evaluation results table\n","    print(results_df)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oZEPFmWlXwFL","executionInfo":{"status":"ok","timestamp":1675540446765,"user_tz":-60,"elapsed":215148,"user":{"displayName":"Jihed Dachraoui","userId":"07546071455318038160"}},"outputId":"92eca107-d1a6-4efb-9798-a437aa80cd28"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 56 images belonging to 4 classes.\n","4/4 [==============================] - 13s 3s/step - loss: 1.2700 - accuracy: 0.6071 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n","              Value\n","Loss       1.269993\n","Accuracy   0.607143\n","Precision  0.000000\n","Recall     0.000000\n","F1-Score   0.000000\n","Found 54 images belonging to 4 classes.\n","4/4 [==============================] - 14s 3s/step - loss: 1.7190 - accuracy: 0.2963 - precision: 0.1458 - recall: 0.1458 - f1_score: 0.1458\n","              Value\n","Loss       1.719028\n","Accuracy   0.296296\n","Precision  0.145833\n","Recall     0.145833\n","F1-Score   0.145833\n","Found 84 images belonging to 4 classes.\n","6/6 [==============================] - 19s 3s/step - loss: 1.4167 - accuracy: 0.2738 - precision: 0.0952 - recall: 0.0952 - f1_score: 0.0952\n","              Value\n","Loss       1.416685\n","Accuracy   0.273810\n","Precision  0.095238\n","Recall     0.095238\n","F1-Score   0.095238\n","Found 66 images belonging to 4 classes.\n","5/5 [==============================] - 19s 3s/step - loss: 1.6568 - accuracy: 0.3636 - precision: 0.2743 - recall: 0.2743 - f1_score: 0.2743\n","              Value\n","Loss       1.656759\n","Accuracy   0.363636\n","Precision  0.274286\n","Recall     0.274286\n","F1-Score   0.274286\n","Found 98 images belonging to 4 classes.\n","7/7 [==============================] - 21s 3s/step - loss: 1.3127 - accuracy: 0.4286 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n","              Value\n","Loss       1.312664\n","Accuracy   0.428571\n","Precision  0.000000\n","Recall     0.000000\n","F1-Score   0.000000\n"]}]},{"cell_type":"code","source":["df = pd.DataFrame(R1)\n","df.to_csv('/content/gdrive/MyDrive/Dataset/output/eval/stats_tuned_{}.csv'.format(model_name), index=False)"],"metadata":{"id":"yuPDoh1VaHYU"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1qLvLMwrvpPAlBXkJLTf-8FvKgIMRyCe3","timestamp":1675529944312}],"authorship_tag":"ABX9TyN23bkL+nx1Qp3BL7WFHsUa"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}