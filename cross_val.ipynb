{"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3203,"status":"ok","timestamp":1675518078560,"user":{"displayName":"Jihed Dachraoui","userId":"07546071455318038160"},"user_tz":-60},"id":"7aQOUKkB03-E","outputId":"e8bba45f-be84-45ff-80b2-5a69920aeb70"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["import sys\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","import numpy as np \n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import seaborn as sns\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import auc\n","import cv2\n","import pickle \n","from sklearn.metrics import accuracy_score\n","import shutil\n","# Keras Libraries\n","import keras\n","import tensorflow as tf\n","from keras import backend as K\n","from keras import metrics\n","from tensorflow.keras.utils import load_img, img_to_array\n","from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n","from keras.regularizers import l2\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, InputLayer, Activation\n","from keras.utils import  load_img\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.metrics import AUC\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.preprocessing import label_binarize\n","from sklearn.metrics import classification_report, roc_auc_score\n","import keras.backend\n","import os\n","import random\n","import time\n","import datetime\n","from tensorflow.python.framework import ops\n","import inspect\n","import gc\n","import tensorflow_hub as hub"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1675518078560,"user":{"displayName":"Jihed Dachraoui","userId":"07546071455318038160"},"user_tz":-60},"id":"uAPdzWZ74BNv"},"outputs":[],"source":["batch_size =16\n"]},{"cell_type":"code","source":["from sklearn.utils import class_weight as cw\n","\n","def get_weight(t):\n","    class_weight_current =  cw.compute_class_weight('balanced', classes=np.unique(t), y=t)\n","    return class_weight_current\n"],"metadata":{"id":"AoYkNsAwjhHq","executionInfo":{"status":"ok","timestamp":1675518078561,"user_tz":-60,"elapsed":3,"user":{"displayName":"Jihed Dachraoui","userId":"07546071455318038160"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":514,"status":"ok","timestamp":1675518079072,"user":{"displayName":"Jihed Dachraoui","userId":"07546071455318038160"},"user_tz":-60},"id":"2PwqKRFA6hpy"},"outputs":[],"source":["model_name='vgg16'\n","base_model = tf.keras.applications.VGG16(\n","                     include_top=False,\n","                     weights='imagenet',\n","                     input_shape=(300, 600,3),\n","                     \n","                     )\n"," \n","#base_model.trainable=True\n","for layer in base_model.layers:\n","        layer.trainable=False\n","# For freezing the layer we make use of layer.trainable = False\n","# means that its internal state will not change during training.\n","# model's trainable weights will not be updated during fit(),\n","# and also its state updates will not run.\n"," \n","model = tf.keras.Sequential([\n","        base_model , \n","        \n","        #tf.keras.layers.BatchNormalization(renorm=True),\n","        tf.keras.layers.GlobalAveragePooling2D(),\n","        #tf.keras.layers.Flatten(),\n","        tf.keras.layers.Dense(1024, activation='relu'),\n","        tf.keras.layers.Dense(512, activation='relu'),\n","        #tf.keras.layers.Dense(256, activation='relu'),\n","        \n","        #tf.keras.layers.Dense(128, activation='relu'),\n","\n","        #tf.keras.layers.Dense(60, activation='relu'),\n","        \n","        \n","        tf.keras.layers.Dropout(0.5),\n","        tf.keras.layers.Dense(4, activation='softmax')\n","    ])"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1675518079072,"user":{"displayName":"Jihed Dachraoui","userId":"07546071455318038160"},"user_tz":-60},"id":"SxhMnWqg6DKm","outputId":"9707d77d-b162-432d-ec32-24eb4a690bb8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," vgg16 (Functional)          (None, 9, 18, 512)        14714688  \n","                                                                 \n"," global_average_pooling2d_1   (None, 512)              0         \n"," (GlobalAveragePooling2D)                                        \n","                                                                 \n"," dense_3 (Dense)             (None, 1024)              525312    \n","                                                                 \n"," dense_4 (Dense)             (None, 512)               524800    \n","                                                                 \n"," dropout_1 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_5 (Dense)             (None, 4)                 2052      \n","                                                                 \n","=================================================================\n","Total params: 15,766,852\n","Trainable params: 1,052,164\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1675518079072,"user":{"displayName":"Jihed Dachraoui","userId":"07546071455318038160"},"user_tz":-60},"id":"S-iaFG-IZX77"},"outputs":[],"source":["accuracies = []\n","stats=[]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZfXIXLUM9sER"},"outputs":[],"source":["epochs=50\n","\n","# Define the path to the 5 folds\n","folders = [\"/content/gdrive/MyDrive/Dataset/data_fold4\",\"/content/gdrive/MyDrive/Dataset/data_fold3\", \"/content/gdrive/MyDrive/Dataset/data_fold2\",\"/content/gdrive/MyDrive/Dataset/data_fold1\",\"/content/gdrive/MyDrive/Dataset/data_fold0\"]\n","\n","# Initialize a list to store the accuracy scores\n","\n","\n","# Iterate over the 5 folds\n","for fold in folders:\n","\n","    fold_name = fold.split(\"/\")[-1]\n","    early = tf.keras.callbacks.EarlyStopping( patience=25,\n","                                          min_delta=0.001,\n","                                              restore_best_weights=True)\n","    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n","        filepath=\"/content/gdrive/MyDrive/Dataset/output/checkpoints/Modelmax+min__{}_{}.h5\".format(model_name,fold_name),\n","      save_best_only=True,\n","       restore_best_weights=True,\n","        verbose=1\n","    )\n","    reduce1=tf.keras.callbacks.ReduceLROnPlateau(factor=0.1,  # reduce the learning rate by a factor of 0.1\n","        patience=10,  \n","        \n","        verbose=1)\n","    callbacks=[early,checkpoint,reduce1]\n","\n","\n","\n","    train_path = fold + r\"/train\"\n","   \n","    test_path = fold + r\"/test\"\n","\n","    # Define the data generator\n","    datagen = ImageDataGenerator( rescale=1.0/255.0,\n","                                   shear_range = 0.02,\n","                                   zoom_range = 0.02, rotation_range=10,\n","                                  fill_mode='nearest',\n","                                  width_shift_range=0.1,\n","                                  height_shift_range=0.1\n","                                 )\n","\n","    # Define the generator that will read images from the fold directory and their labels\n","    \n","    train_generator = datagen.flow_from_directory(directory = train_path, \n","                                                        color_mode=\"rgb\",\n","                                                        target_size = (300, 600), # image height , image width\n","                                                        class_mode=\"categorical\",\n","                                                        batch_size=batch_size,\n","                                                        shuffle=True,\n","                                                        seed=42)\n","    \n","    test_generator = datagen.flow_from_directory(directory = test_path, \n","                                                    color_mode=\"rgb\",\n","                                                        target_size = (300, 600), # image height , image width\n","                                                        class_mode=\"categorical\",\n","                                                        batch_size=batch_size,\n","                                                        shuffle=True,\n","                                                        seed=42)\n","\n","    test_generator.reset()\n","    train_classes = train_generator.classes\n","\n","    class_weights =  get_weight(train_classes)\n","    Class_weight = dict(zip(np.unique(train_classes), class_weights))\n","\n","\n","    model.compile(optimizer=keras.optimizers.Adam(learning_rate=.0001),loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","    STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n","    STEP_SIZE_VALID = test_generator.n//test_generator.batch_size\n","    # Train the model on the images in the fold\n","    model.fit(train_generator,\n","                    steps_per_epoch=STEP_SIZE_TRAIN,\n","                    validation_data=test_generator,\n","                    validation_steps=STEP_SIZE_VALID,\n","                    epochs=epochs,\n","                    callbacks=callbacks,\n","              class_weight=Class_weight)\n","    \n","\n","\n","\n","    model.save(\"/content/gdrive/MyDrive/Dataset/output/tmp/models/Modelmax+min__{}_{}.h5\".format(model_name,fold_name))\n","\n","\n","\n","    train_loss = model.history.history['loss']\n","    val_loss = model.history.history['val_loss']\n","    #print(list(cnn_model.history.keys()))\n","    ## Define train & validation AUC\n","    train_auc_name = list(model.history.history.keys())[1]\n","    val_auc_name = list(model.history.history.keys())[3]\n","    train_auc = model.history.history[train_auc_name]\n","    val_auc = model.history.history[val_auc_name]\n","\n","    # Make predictions on the test data\n","    y_pred = model.predict(test_generator, steps = len(test_generator))\n","    y_pred = np.argmax(y_pred, axis=1)\n","    y_true = test_generator.classes\n","\n","    fig = plt.figure(figsize=(13, 10))\n","    ## PLOT 1: TRAIN VS. VALIDATION LOSS \n","    plt.subplot(2,2,1)\n","    plt.title(\"Training vs. Validation Loss\")\n","    plt.plot(train_loss, label='training loss')\n","    plt.plot(val_loss, label='validation loss')\n","    plt.xlabel(\"Number of Epochs\", size=14)\n","    plt.legend()\n","\n","    ## PLOT 2: TRAIN VS. VALIDATION AUC\n","    plt.subplot(2,2,2)\n","    plt.title(\"Training vs. Validation Acc Score\")\n","    plt.plot(train_auc, label='training acc')\n","    plt.plot(val_auc, label='validation acc')\n","    plt.xlabel(\"Number of Epochs\", size=14)\n","    plt.legend()\n","    \n","    ## PLOT 3: CONFUSION MATRIX\n","    plt.subplot(2,2,3)\n","    # Set up the labels for in the confusion matrix\n","    cm = confusion_matrix(y_true, y_pred,labels=[0,1,2,3])\n","    names = ['True Negatives', 'False Positives', 'False Negatives', 'True Positives']\n","    counts = ['{0:0.0f}'.format(value) for value in cm.flatten()]\n","    #print(counts)\n","    percentages = ['{0:.2%}'.format(value) for value in cm.flatten()/np.sum(cm)]\n","    labels = [[f'{names[i]}\\n{percentages[i]}' for i in range(len(names))] for j in range(len(cm))]\n","    #print(labels)\n","    #labels = np.asarray(labels).reshape(2,2)\n","    ticklabels = ['socre0', 'socre1','socre2','socre3']\n","    #print(cm)\n","    #print(labels)\n","    # Create confusion matrix as heatmap\n","    sns.set(font_scale = 1.4)\n","    ax = sns.heatmap(cm, annot=True, fmt='', cmap='Oranges', xticklabels=ticklabels, yticklabels=ticklabels )\n","    plt.xticks(size=12)\n","    plt.yticks(size=12)\n","    plt.title(\"Confusion Matrix\") #plt.title(\"Confusion Matrix\\n\", fontsize=10)\n","    plt.xlabel(\"Predicted\", size=14)\n","    plt.ylabel(\"Actual\", size=14)\n","    if os.path.exists('/content/gdrive/MyDrive/Dataset/output/figures/Modelmax+min__{}_{}.jpg'.format(model_name,fold_name)):\n","      os.remove('/content/gdrive/MyDrive/Dataset/output/figures/Modelmax+min__{}_{}.jpg'.format(model_name,fold_name))\n","    plt.savefig('/content/gdrive/MyDrive/Dataset/output/figures/Modelmax+min__{}_{}.jpg'.format(model_name,fold_name))\n","    plt.close()\n","    # Evaluate the model's performance\n","    accuracy = accuracy_score(test_generator.classes, y_pred)\n","    accuracies.append(accuracy)\n","    df = pd.DataFrame(accuracies)\n","    df.to_csv('/content/gdrive/MyDrive/Dataset/output/accuracy_{}_{}.csv'.format(model_name,fold_name), index=False)\n","    accuracy = np.trace(cm) / np.sum(cm)\n","    precision = np.diag(cm) / np.sum(cm, axis = 0)\n","    precision = np.mean(precision)  \n","    recall = np.diag(cm) / np.sum(cm, axis = 1)\n","    recall = np.mean(recall)\n","    f1 = 2 * (precision * recall) / (precision + recall)\n","    TN = np.sum(np.diag(cm)) - np.sum(cm)\n","    FP = np.sum(cm, axis=0) - np.diag(cm)\n","    specificity = TN / (TN+FP) # % negative out of all supposed to be negatives\n","    specificity = np.mean(specificity)\n","    \n","    stats_summary = '[Summary Statistics]\\nAccuracy = {:.2%} | Precision = {:.2%} | Recall = {:.2%} | Specificity = {:.2%} | F1 Score = {:.2%}'.format(accuracy, precision, recall, specificity, f1)\n","    stats.append(stats_summary)\n","# Print the mean accuracy\n","print(\"Mean Accuracy: {:.2f}%\".format(np.mean(accuracies) * 100))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sQJEdGsfZLcb"},"outputs":[],"source":["accuracies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lXSFLAzqVsmN"},"outputs":[],"source":["stats"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hO6JvAAlZ0GD"},"outputs":[],"source":["\n","df = pd.DataFrame(accuracies)\n","df.to_csv('/content/gdrive/MyDrive/Dataset/output/{}_accuracies.csv'.format(model_name), index=False)\n","df = pd.DataFrame(stats)\n","df.to_csv('/content/gdrive/MyDrive/Dataset/output/{}_stats.csv'.format(model_name), index=False)"]},{"cell_type":"markdown","source":["# fine tuning\n"],"metadata":{"id":"SuowvSBduwSr"}},{"cell_type":"code","source":["accuracies=[]"],"metadata":{"id":"Js4I87wa6I99"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs=50\n","\n","# Define the path to the 5 folds\n","folders = [\"/content/gdrive/MyDrive/Dataset/data_fold4\",\"/content/gdrive/MyDrive/Dataset/data_fold3\", \"/content/gdrive/MyDrive/Dataset/data_fold2\",\"/content/gdrive/MyDrive/Dataset/data_fold1\",\"/content/gdrive/MyDrive/Dataset/data_fold0\"]\n","\n","# Initialize a list to store the accuracy scores\n","\n","\n","# Iterate over the 5 folds\n","for fold in folders:\n","\n","    fold_name = fold.split(\"/\")[-1]\n","    fold_name1 = fold.split(\"_\")[-1]\n","\n","\n","\n","\n","    model= tf.keras.models.load_model(\"/content/gdrive/MyDrive/Dataset/output/models/Modelmax+min__mobilnetv2_{}.h5\".format(fold_name))\n","    for layer in model.layers:\n","        layer.trainable=True\n","    model.summary()\n","    model.compile(tf.keras.optimizers.RMSprop(learning_rate=.000001),loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","\n","\n","\n","\n","\n","    early = tf.keras.callbacks.EarlyStopping( patience=25,\n","                                          min_delta=0.001,\n","                                              restore_best_weights=True)\n","    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n","        filepath=\"/content/gdrive/MyDrive/Dataset/output/checkpoints/Modelmax+min__mobilnetv2_finetuned_{}.h5\".format(fold_name),\n","      save_best_only=True,\n","       restore_best_weights=True,\n","        verbose=1\n","    )\n","    reduce1=tf.keras.callbacks.ReduceLROnPlateau(factor=0.1,  # reduce the learning rate by a factor of 0.1\n","        patience=10,  \n","        \n","        verbose=1)\n","    callbacks=[early,checkpoint,reduce1]\n","\n","\n","\n","\n","\n","    train_path = fold + r\"/train\"\n","   \n","    test_path = fold + r\"/test\"\n","\n","    # Define the data generator\n","    datagen = ImageDataGenerator( rescale=1.0/255.0,\n","                                    rotation_range=5,\n","                                 )\n","\n","    # Define the generator that will read images from the fold directory and their labels\n","    \n","    train_generator = datagen.flow_from_directory(directory = train_path, \n","                                                        color_mode=\"rgb\",\n","                                                        target_size = (300, 600), # image height , image width\n","                                                        class_mode=\"categorical\",\n","                                                        batch_size=batch_size,\n","                                                        shuffle=True,\n","                                                        seed=42)\n","    \n","    test_generator = datagen.flow_from_directory(directory = test_path, \n","                                                    color_mode=\"rgb\",\n","                                                        target_size = (300, 600), # image height , image width\n","                                                        class_mode=\"categorical\",\n","                                                        batch_size=batch_size,\n","                                                        shuffle=True,\n","                                                        seed=42)\n","\n","    test_generator.reset()\n","   \n","    \n","\n","    STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n","    STEP_SIZE_VALID = test_generator.n//test_generator.batch_size\n","    # Train the model on the images in the fold\n","    model.fit(train_generator,\n","                    steps_per_epoch=STEP_SIZE_TRAIN,\n","                    validation_data=test_generator,\n","                    validation_steps=STEP_SIZE_VALID,\n","                    epochs=epochs,\n","                    callbacks=callbacks,\n","             )\n","    \n","\n","\n","\n","    model.save(\"/content/gdrive/MyDrive/Dataset/output/models/Modelmax+min__mobilnetv2_finetuned_{}.h5\".format(fold_name))\n","\n","\n","\n","    train_loss = model.history.history['loss']\n","    val_loss = model.history.history['val_loss']\n","    #print(list(cnn_model.history.keys()))\n","    ## Define train & validation AUC\n","    train_auc_name = list(model.history.history.keys())[1]\n","    val_auc_name = list(model.history.history.keys())[3]\n","    train_auc = model.history.history[train_auc_name]\n","    val_auc = model.history.history[val_auc_name]\n","\n","    # Make predictions on the test data\n","    y_pred = model.predict(test_generator, steps = len(test_generator))\n","    y_pred = np.argmax(y_pred, axis=1)\n","    y_true = test_generator.classes\n","\n","    fig = plt.figure(figsize=(13, 10))\n","    ## PLOT 1: TRAIN VS. VALIDATION LOSS \n","    plt.subplot(2,2,1)\n","    plt.title(\"Training vs. Validation Loss\")\n","    plt.plot(train_loss, label='training loss')\n","    plt.plot(val_loss, label='validation loss')\n","    plt.xlabel(\"Number of Epochs\", size=14)\n","    plt.legend()\n","\n","    ## PLOT 2: TRAIN VS. VALIDATION AUC\n","    plt.subplot(2,2,2)\n","    plt.title(\"Training vs. Validation Acc Score\")\n","    plt.plot(train_auc, label='training acc')\n","    plt.plot(val_auc, label='validation acc')\n","    plt.xlabel(\"Number of Epochs\", size=14)\n","    plt.legend()\n","    \n","    ## PLOT 3: CONFUSION MATRIX\n","    plt.subplot(2,2,3)\n","    # Set up the labels for in the confusion matrix\n","    cm = confusion_matrix(y_true, y_pred,labels=[0,1,2,3])\n","    names = ['True Negatives', 'False Positives', 'False Negatives', 'True Positives']\n","    counts = ['{0:0.0f}'.format(value) for value in cm.flatten()]\n","    #print(counts)\n","    percentages = ['{0:.2%}'.format(value) for value in cm.flatten()/np.sum(cm)]\n","    labels = [[f'{names[i]}\\n{percentages[i]}' for i in range(len(names))] for j in range(len(cm))]\n","    #print(labels)\n","    #labels = np.asarray(labels).reshape(2,2)\n","    ticklabels = ['socre0', 'socre1','socre2','socre3']\n","    #print(cm)\n","    #print(labels)\n","    # Create confusion matrix as heatmap\n","    sns.set(font_scale = 1.4)\n","    ax = sns.heatmap(cm, annot=True, fmt='', cmap='Oranges', xticklabels=ticklabels, yticklabels=ticklabels )\n","    plt.xticks(size=12)\n","    plt.yticks(size=12)\n","    plt.title(\"Confusion Matrix\") #plt.title(\"Confusion Matrix\\n\", fontsize=10)\n","    plt.xlabel(\"Predicted\", size=14)\n","    plt.ylabel(\"Actual\", size=14)\n","    if os.path.exists('/content/gdrive/MyDrive/Dataset/output/figures/Modelmax+min__mobilnetv2_finetuned_{}.jpg'.format(fold_name)):\n","      os.remove('/content/gdrive/MyDrive/Dataset/output/figures/Modelmax+min__mobilnetv2_finetuned_{}.jpg'.format(fold_name))\n","    plt.savefig('/content/gdrive/MyDrive/Dataset/output/figures/Modelmax+min__mobilnetv2_finetuned_{}.jpg'.format(fold_name))\n","    plt.close()\n","    # Evaluate the model's performance\n","    accuracy = accuracy_score(test_generator.classes, y_pred)\n","    accuracies.append(accuracy)\n","    df = pd.DataFrame(accuracies)\n","    df.to_csv('/content/gdrive/MyDrive/Dataset/output/accuracy_mobilnetv2_finetuned_{}.csv'.format(fold_name), index=False)\n","    accuracy = np.trace(cm) / np.sum(cm)\n","    precision = np.diag(cm) / np.sum(cm, axis = 0)\n","    precision = np.mean(precision)  \n","    recall = np.diag(cm) / np.sum(cm, axis = 1)\n","    recall = np.mean(recall)\n","    f1 = 2 * (precision * recall) / (precision + recall)\n","    TN = np.sum(np.diag(cm)) - np.sum(cm)\n","    FP = np.sum(cm, axis=0) - np.diag(cm)\n","    specificity = TN / (TN+FP) # % negative out of all supposed to be negatives\n","    specificity = np.mean(specificity)\n","    \n","    stats_summary = '[Summary Statistics]\\nAccuracy = {:.2%} | Precision = {:.2%} | Recall = {:.2%} | Specificity = {:.2%} | F1 Score = {:.2%}'.format(accuracy, precision, recall, specificity, f1)\n","    stats.append(stats_summary)\n","# Print the mean accuracy\n","print(\"Mean Accuracy: {:.2f}%\".format(np.mean(accuracies) * 100))"],"metadata":{"id":"Lc4yagJGyQKL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.DataFrame(accuracies)\n","df.to_csv('/content/gdrive/MyDrive/Dataset/output/mobilnetv2_finetuned_accuracies.csv', index=False)\n","df = pd.DataFrame(stats)\n","df.to_csv('/content/gdrive/MyDrive/Dataset/output/mobilnetv2_finetuned_stats.csv', index=False)"],"metadata":{"id":"HRGggf-his0u"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNGGU6W8kI8h4a82ZB/0YzO"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}