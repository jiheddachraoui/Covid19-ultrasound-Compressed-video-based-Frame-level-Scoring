{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiheddachraoui/Covid19-ultrasound-video-scoring/blob/main/Database_ordering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPYKPiC_vj_c"
      },
      "source": [
        "## Importations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFuXhsc9GeUv",
        "outputId": "20101cf8-2f3e-44c0-9f77-9cf34962c850"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import sys \n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "from datetime import timedelta\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import KFold \n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.io import loadmat\n",
        "from PIL import Image\n",
        "import imageio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzWmkagTaIV4",
        "outputId": "96c94f51-ed6f-464e-9962-438135d75408"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta_oXqsDvsLh"
      },
      "source": [
        "# Copying Data to Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hKFOVpAJqxB"
      },
      "outputs": [],
      "source": [
        "source_dir = r\"/content/gdrive/MyDrive/Dati San Matteo Dataset 2\"\n",
        "destination_dir = r\"/content/gdrive/MyDrive/Dataset\"\n",
        "#create a copy of the dataset\n",
        "#shutil.copytree(source_dir, destination_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBIie2TvwACQ"
      },
      "source": [
        "## Copying all data in one folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDQIyrG-0Dyd"
      },
      "source": [
        "###videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IK7hStjtW-7G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "efa37038-7924-4e21-b6ff-7aa8969a00d2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-6db406b84f37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/MyDrive/Dataset/videos\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/MyDrive/Dataset/videos\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mexams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mvideos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 107] Transport endpoint is not connected: '/content/gdrive/MyDrive/Dataset'"
          ]
        }
      ],
      "source": [
        "folder_path = \"/content/gdrive/MyDrive/Dataset\"\n",
        "if os.path.exists(\"/content/gdrive/MyDrive/Dataset/videos\"):\n",
        "  shutil.rmtree(\"/content/gdrive/MyDrive/Dataset/videos\")\n",
        "files = [f for f in os.listdir(folder_path) if not os.path.isfile(os.path.join(folder_path, f))]\n",
        "exams=[]\n",
        "videos=[]\n",
        "vid_path=[]\n",
        "for f in files:\n",
        "    path = os.path.join(folder_path,f)\n",
        "    for e in os.listdir(path):\n",
        "\n",
        "      if not os.path.isfile(os.path.join(path, e)):\n",
        "        exams.append(e)\n",
        "        path1 = os.path.join(path,e)\n",
        "        \n",
        "        for v in os.listdir(path1):\n",
        "          \n",
        "          if os.path.isfile(os.path.join(path1, v)) and v.split('.')[1]==\"avi\" :\n",
        "            videos.append(v)\n",
        "            vid_path.append(path1)\n",
        "            \n",
        " \n",
        "#len(videos)\n",
        "len(vid_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7n91YFPOg9o"
      },
      "outputs": [],
      "source": [
        "i=0\n",
        "for video in videos:\n",
        "    folder_type = video.split('.')[1]\n",
        "    patient_name = video.split('_')[1]\n",
        "    exam = video.split('_')[2]\n",
        "    new_path = os.path.join(videos_path, patient_name+'-'+exam)\n",
        "    if not os.path.exists(new_path):\n",
        "        os.makedirs(new_path)\n",
        "    \n",
        "    old_video_path = os.path.join(vid_path[i], video)\n",
        "    new_video_path = os.path.join(new_path, video)\n",
        "    if not os.path.exists(new_video_path):\n",
        "      shutil.copy(old_video_path, new_video_path)\n",
        "      print('video',video ,'added to',new_video_path)\n",
        "    i+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Int7uQTu0U3X"
      },
      "source": [
        "### videos frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmTopPyd0hk6"
      },
      "outputs": [],
      "source": [
        "folder_path = \"/content/gdrive/MyDrive/Dataset\"\n",
        "\n",
        "files = [f for f in os.listdir(folder_path) if not os.path.isfile(os.path.join(folder_path, f))]\n",
        "exams=[]\n",
        "frames=[]\n",
        "f_path=[]\n",
        "for f in files:\n",
        "    path = os.path.join(folder_path,f)\n",
        "    for e in os.listdir(path):\n",
        "\n",
        "      if not os.path.isfile(os.path.join(path, e)):\n",
        "        exams.append(e)\n",
        "        path1 = os.path.join(path,e)\n",
        "        \n",
        "        for v in os.listdir(path1):\n",
        "          \n",
        "          if os.path.isfile(os.path.join(path1, v)) and v.split('.')[1]==\"mat\" and len(v.split('_'))==4 :\n",
        "            \n",
        "            frames.append(v)\n",
        "            f_path.append(os.path.join(path1, v))\n",
        "            \n",
        " \n",
        "#len(videos)\n",
        "len(f_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9X0fZSF0amr4"
      },
      "outputs": [],
      "source": [
        "frames_path='/content/gdrive/MyDrive/Dataset/frames'\n",
        "i=0\n",
        "\n",
        "for f in frames:\n",
        "    folder_type = f.split('.')[1]\n",
        "    patient_name = f.split('_')[1]\n",
        "    exam = f.split('_')[2]\n",
        "    new_path = os.path.join(frames_path, patient_name+'-'+exam)\n",
        "    if not os.path.exists(new_path):\n",
        "        os.makedirs(new_path)\n",
        "    \n",
        "    old_file_path = f_path[i]\n",
        "    new_file_path = os.path.join(new_path, f)\n",
        "    if not os.path.exists(new_file_path):\n",
        "      shutil.copy(old_file_path, new_file_path)\n",
        "      print('video frames',f ,'added to',new_file_path)\n",
        "    i+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea1EbvAhvL-3"
      },
      "source": [
        "# Frames extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uF_G0Sl_GwsL"
      },
      "outputs": [],
      "source": [
        "SAVING_FRAMES_PER_SECOND = 10\n",
        "def format_timedelta(td):\n",
        "    \"\"\"Utility function to format timedelta objects in a cool way (e.g 00:00:20.05) \n",
        "    omitting microseconds and retaining milliseconds\"\"\"\n",
        "    result = str(td)\n",
        "    try:\n",
        "        result, ms = result.split(\".\")\n",
        "    except ValueError:\n",
        "        return result + \".00\".replace(\":\", \"-\")\n",
        "    ms = int(ms)\n",
        "    ms = round(ms / 1e4)\n",
        "    return f\"{result}.{ms:02}\".replace(\":\", \"-\")\n",
        "\n",
        "\n",
        "def get_saving_frames_durations(cap, saving_fps):\n",
        "    \"\"\"A function that returns the list of durations where to save the frames\"\"\"\n",
        "    s = []\n",
        "    # get the clip duration by dividing number of frames by the number of frames per second\n",
        "    clip_duration = cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS)\n",
        "    # use np.arange() to make floating-point steps\n",
        "    for i in np.arange(0, clip_duration, 1 / saving_fps):\n",
        "        s.append(i)\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgmyjZawHiGo"
      },
      "outputs": [],
      "source": [
        "def extract(video_file):\n",
        "    filename, _ = os.path.splitext(video_file)\n",
        "    filename += \"-Frames\"\n",
        "    print(filename)\n",
        "    # make a folder by the name of the video file\n",
        "    if not os.path.isdir(filename):\n",
        "        os.mkdir(filename)\n",
        "    # read the video file    \n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "    # get the FPS of the video\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    # if the SAVING_FRAMES_PER_SECOND is above video FPS, then set it to FPS (as maximum)\n",
        "    saving_frames_per_second = min(fps, SAVING_FRAMES_PER_SECOND)\n",
        "    # get the list of duration spots to save\n",
        "    saving_frames_durations = get_saving_frames_durations(cap, saving_frames_per_second)\n",
        "    # start the loop\n",
        "    count = 0\n",
        "    while True:\n",
        "        is_read, frame = cap.read()\n",
        "        if not is_read:\n",
        "            # break out of the loop if there are no frames to read\n",
        "            break\n",
        "        # get the duration by dividing the frame count by the FPS\n",
        "        frame_duration = count / fps\n",
        "        try:\n",
        "            # get the earliest duration to save\n",
        "            closest_duration = saving_frames_durations[0]\n",
        "        except IndexError:\n",
        "            # the list is empty, all duration frames were saved\n",
        "            break\n",
        "        if frame_duration >= closest_duration:\n",
        "            # if closest duration is less than or equals the frame duration, \n",
        "            # then save the frame\n",
        "            frame_duration_formatted = format_timedelta(timedelta(seconds=frame_duration))\n",
        "            cv2.imwrite(os.path.join(filename, f\"frame{frame_duration_formatted}.jpg\"), frame)\n",
        "            print(os.path.join(filename, f\"frame{frame_duration_formatted}.jpg\"), 'saved') \n",
        "            # drop the duration spot from the list, since this duration spot is already saved\n",
        "            try:\n",
        "                saving_frames_durations.pop(0)\n",
        "            except IndexError:\n",
        "                pass\n",
        "        # increment the frame count\n",
        "        count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZprdpL2Hm_8"
      },
      "outputs": [],
      "source": [
        "videos_path='/content/gdrive/MyDrive/Dataset/videos'\n",
        "video_files=[]\n",
        "files = [os.path.join(videos_path,f) for f in os.listdir(videos_path)]\n",
        "for f in files:\n",
        "  for v in os.listdir(f):\n",
        "    if os.path.isfile(os.path.join(f,v)):\n",
        "      video_file=os.path.join(f,v)\n",
        "      video_files.append(video_file)\n",
        "    \n",
        "\n",
        "for video_file in video_files:\n",
        "  extract(video_file) \n",
        "  print('next video__________________________________________________________________________')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on6VfOzTu83F"
      },
      "source": [
        "# Count files in folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hUIsa8jfZbfc"
      },
      "outputs": [],
      "source": [
        "def count_files(path):\n",
        "  count = 0\n",
        "\n",
        "  for f in os.listdir(path):\n",
        "      # check if current path is a file\n",
        "      if os.path.isfile(os.path.join(path, f)):\n",
        "          count += 1\n",
        "  #print('File count:', count)\n",
        "  return count\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FtkO9Reux6w"
      },
      "source": [
        "# Max-Min images generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppTGDSoV3o3T"
      },
      "outputs": [],
      "source": [
        "\n",
        "def vid_max_min_frame_generator(vid_path):\n",
        "  filename, _ = os.path.splitext(video_file)\n",
        "  filename += \"-MAXMIN\"\n",
        "  if not os.path.isdir(filename):\n",
        "        os.mkdir(filename)\n",
        "  cap = cv2.VideoCapture(vid_path)\n",
        "  frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "  frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "  buf = np.empty((frameCount, frameHeight, frameWidth, 3), np.dtype('uint8'))\n",
        "\n",
        "  fc = 0\n",
        "  ret = True\n",
        "\n",
        "  while (fc < frameCount  and ret):\n",
        "      ret, buf[fc] = cap.read()\n",
        "      fc += 1\n",
        "\n",
        "  cap.release()\n",
        "  \n",
        "  try:\n",
        "    Max=np.max(buf,axis=0)\n",
        "    Min=np.min(buf,axis=0)\n",
        "   \n",
        "    #plt.imshow(Max)\n",
        "    #print(Max.shape)\n",
        "  \n",
        "    #plt.show()\n",
        "    #plt.imshow(Min)\n",
        "    #print(Min.shape)\n",
        "    #plt.show()\n",
        "    cv2.imwrite(os.path.join(filename,\"Max.jpg\"), Max)\n",
        "    print(os.path.join(filename,\"-Max.jpg\"))\n",
        "    cv2.imwrite(os.path.join(filename,\"Min.jpg\"), Min)\n",
        "    print(os.path.join(filename,\"-Min.jpg\"), 'saved')\n",
        "  \n",
        "  except ValueError:  \n",
        "      pass\n",
        " ################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def matrix_max_min_frame_generator(file_path):\n",
        "  filename=file_path.split('/')[-1]\n",
        "  filename=filename.split('.')[0]\n",
        "  filename1, _ = os.path.splitext(file_path)\n",
        "  filename1 =filename1+ \"-MAXMIN\"\n",
        "  \n",
        "  if not os.path.isdir(filename1):\n",
        "        os.mkdir(filename1)\n",
        "  f = loadmat(file_path)\n",
        "  frames=f['frames']\n",
        "  #frames.shape\n",
        "  \n",
        "  Max=np.max(frames,axis=3)\n",
        "  Min=np.min(frames,axis=3)\n",
        "  #plt.imshow(Max)\n",
        "  #print(Max.shape)\n",
        " # plt.show()\n",
        "  #plt.imshow(Min)\n",
        "  #print(Min.shape)\n",
        "  #plt.show()\n",
        "  if not os.path.exists(os.path.join(filename1,f\"{filename}-Max.jpg\")) :\n",
        "    cv2.imwrite(os.path.join(filename1,f\"{filename}-Max.jpg\"), Max)\n",
        "    print(os.path.join(filename1,f\"{filename}-Max.jpg\"))\n",
        "  if not os.path.exists(os.path.join(filename1,f\"{filename}-Min.jpg\")) :\n",
        "    cv2.imwrite(os.path.join(filename1,f\"{filename}-Min.jpg\"), Min)\n",
        "    print(os.path.join(filename1,f\"{filename}-Min.jpg\"), 'saved')\n",
        "  \n",
        "  \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMzoabySoyky"
      },
      "source": [
        "# Crop Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8n4MHlzchkd"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Importing Image class from PIL module\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "# Opens a image in RGB mode\n",
        "def crop(image):\n",
        "  im = Image.open(image)\n",
        " \n",
        "  # Setting the points for cropped image\n",
        "  width, height = im.size\n",
        " \n",
        "  # Setting the points for cropped image\n",
        "  left = 400\n",
        "  top = 60\n",
        "  right = 1030\n",
        "  bottom=570\n",
        "  # Cropped image of above dimension\n",
        "  # (It will not change original image)\n",
        "  im1 = im.crop((left, top, right, bottom))\n",
        " \n",
        "  # Shows the image in image viewer\n",
        "  plt.imshow(im)\n",
        "  plt.show()\n",
        "  plt.imshow(im1)\n",
        "  plt.show()\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2owOzhPuQWX"
      },
      "source": [
        "# Data analysis \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2HxHE6OkG7G"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('/content/gdrive/MyDrive/Dataset/SanMatteo.csv')\n",
        "\n",
        "df.hist(bins=50,figsize=(20,15))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTNz2vswuOM-"
      },
      "outputs": [],
      "source": [
        "df2=df[['patient_id','analysis_id','file_area_code','rating_operator']]\n",
        "\n",
        "\n",
        "#df2.sort_values(by=['rating_operator'])\n",
        "df2['video'] ='convex_' +df2['patient_id'].astype(str) + '_' + df2['analysis_id'].astype(str)+ '_' + df2['file_area_code'].astype(str)\n",
        "#df2=df2.set_index(['patient_id','analysis_id','file_area_code'])\n",
        "df2=df2[['video','rating_operator']]\n",
        "#df2=df2.set_index(['video'])\n",
        "df2=df2.reset_index(drop=True)\n",
        "if not os.path.exists('/content/gdrive/MyDrive/Dataset/labels.csv'):\n",
        "  df2.to_csv('/content/gdrive/MyDrive/Dataset/labels.csv') \n",
        "df2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJqsUqXCyLxT"
      },
      "outputs": [],
      "source": [
        "s0=df2[df2['rating_operator']==0]\n",
        "s0.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cyqyw6vAyLpP"
      },
      "outputs": [],
      "source": [
        "s1=df2[df2['rating_operator']==1]\n",
        "s1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1T1cHVKyLXz"
      },
      "outputs": [],
      "source": [
        "s2=df2[df2['rating_operator']==2]\n",
        "s2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8ltO4tW4myf"
      },
      "outputs": [],
      "source": [
        "s3=df2[df2['rating_operator']==3]\n",
        "s3.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1c2NcOqe49JK"
      },
      "outputs": [],
      "source": [
        "df2.hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVh7c3F-uZ52"
      },
      "source": [
        "# Data label organization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Hoibw3YFQVL"
      },
      "outputs": [],
      "source": [
        "#these parameters are defined in the previous section\n",
        "score0 = s0.to_dict(orient = 'list')\n",
        "score1 = s1.to_dict(orient = 'list')\n",
        "score2 = s2.to_dict(orient = 'list')\n",
        "score3 = s3.to_dict(orient = 'list')\n",
        "\n",
        "video0=score0['video']\n",
        "video1=score1['video']\n",
        "video2=score2['video']\n",
        "video3=score3['video']\n",
        "total=video0+video1+video2+video3\n",
        "print(video2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98DrzylyH71C"
      },
      "outputs": [],
      "source": [
        "\n",
        "def score_folder(List,s):\n",
        "  \n",
        "  root_dir = '/content/gdrive/MyDrive/Dataset/data/'\n",
        "  path0=root_dir+s+'/score0'\n",
        "  path1=root_dir+s+'/score1'\n",
        "  path2=root_dir+s+'/score2'\n",
        "  path3=root_dir+s+'/score3'\n",
        "  path=[path0,path1,path2,path3]\n",
        "  videos_path=root_dir+s\n",
        "  for i in path:\n",
        "    if not os.path.exists(i):\n",
        "          os.mkdir(i)\n",
        "  \n",
        "  files = [f for f in os.listdir(videos_path)]\n",
        "  print(files)\n",
        "  for v in files:\n",
        "    \n",
        "      #print(os.path.join(videos_path,v))\n",
        "      if os.path.isfile(os.path.join(videos_path,v)):\n",
        "        \n",
        "        \n",
        "        \n",
        "        if v.split('.')[0] in video0 :\n",
        "       \n",
        "\n",
        "            if not os.path.exists(os.path.join(path0, v)):\n",
        "             \n",
        "              #os.mkdir(path=os.path.join(path, v))\n",
        "              shutil.copy(os.path.join(videos_path,v), os.path.join(path0, v))\n",
        "\n",
        "        elif v.split('.')[0] in video1 :\n",
        "       \n",
        "\n",
        "            if not os.path.exists(os.path.join(path1, v)):\n",
        "              \n",
        "              #os.mkdir(path=os.path.join(path, v))\n",
        "              shutil.copy(os.path.join(videos_path,v), os.path.join(path1, v))\n",
        "\n",
        "        elif v.split('.')[0] in video2 :\n",
        "       \n",
        "\n",
        "            if not os.path.exists(os.path.join(path2, v)):\n",
        "             \n",
        "              #os.mkdir(path=os.path.join(path, v))\n",
        "              shutil.copy(os.path.join(videos_path,v), os.path.join(path2, v))\n",
        "   \n",
        "        elif v.split('.')[0] in video3 :\n",
        "       \n",
        "\n",
        "            if not os.path.exists(os.path.join(path3, v)):\n",
        "              \n",
        "              #os.mkdir(path=os.path.join(path, v))\n",
        "              shutil.copy(os.path.join(videos_path,v), os.path.join(path3, v))\n",
        "              #copy\n",
        "  \n",
        "  \n",
        "\n",
        "'''score_folder('score0',video0,'train')\n",
        "score_folder('score1',video1,'train')\n",
        "score_folder('score2',video2,'train')\n",
        "score_folder('score3',video3,'train')\n",
        "\n",
        "score_folder('score0',video0,'val')\n",
        "score_folder('score1',video1,'val')\n",
        "score_folder('score2',video2,'val')\n",
        "score_folder('score3',video3,'val')\n",
        "\n",
        "score_folder('score0',video0,'test')\n",
        "score_folder('score1',video1,'test')\n",
        "score_folder('score2',video2,'test')\n",
        "score_folder('score3',video3,'test')\n",
        "\n",
        "print('folders with no score',set(x) )\n",
        "#print(count_files(path0)+count_files(path1)+count_files(path2)+count_files(path3))'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOr7pTkq-4mF"
      },
      "outputs": [],
      "source": [
        "\"\"\"frames_path='/content/gdrive/MyDrive/Dataset/frames score'\n",
        "frames_files=[]\n",
        "files = [os.path.join(frames_path,f) for f in os.listdir(frames_path)]\n",
        "for f in files:\n",
        "  for v in os.listdir(f):\n",
        "    if os.path.isfile(os.path.join(f,v)):\n",
        "      file=os.path.join(f,v)\n",
        "      frames_files.append(file)\n",
        "    \n",
        "\n",
        "for file in frames_files:\n",
        "  matrix_max_min_frame_generator(file) \n",
        "  print('next file__________________________________________________________________________')\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeEMnOJIgjzX"
      },
      "source": [
        "# Missing scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZlO_iY6ePWD"
      },
      "outputs": [],
      "source": [
        "videos_path='/content/gdrive/MyDrive/Dataset/frames'\n",
        "x=[]\n",
        "m=[]\n",
        "videos=[]\n",
        "\n",
        "for root, dirs, files in os.walk(videos_path, topdown=False):\n",
        "   for v in files:\n",
        "     videos.append(v.split('.')[0])\n",
        "     if v.split('.')[0] not in total :\n",
        "          x.append(v.split('.')[0])\n",
        "print('videos without label= ',x)     \n",
        "  \n",
        "for i in total:\n",
        "  if i not in videos:\n",
        "    m.append(i)\n",
        "\n",
        "print('labels without video=',m)   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1ti_iYiUj2L"
      },
      "source": [
        "# Data split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsJ6jRiKTriu"
      },
      "source": [
        "## K-fold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhpKA7tfJ-X9"
      },
      "outputs": [],
      "source": [
        "k=5\n",
        "df=pd.read_csv('/content/gdrive/MyDrive/Dataset/SanMatteo.csv')\n",
        "df=df[['patient_id','analysis_id','file_area_code','rating_operator']]\n",
        "\n",
        "TRAIN_SPLIT_PERC = 0.7  #0.7\n",
        "VALID_SPLIT_PERC = 0.21 #0.21\n",
        "folds=[]\n",
        "id=\"patient_id\"\n",
        "for i in range(k):\n",
        "    \n",
        "    uniques = df[id].unique()\n",
        "    random.shuffle(uniques)\n",
        "    step = int(len(uniques) * TRAIN_SPLIT_PERC)\n",
        "    step1=int(len(uniques) * (TRAIN_SPLIT_PERC+VALID_SPLIT_PERC))\n",
        "    df = df.sample(frac=1).reset_index(drop=True) #shuffling data\n",
        "    train_ids, valid_ids,test_ids = uniques[:step], uniques[step:step1],uniques[step1:]\n",
        "    \n",
        "\n",
        "\n",
        "   \n",
        "    fold=[list(train_ids),list(valid_ids),list(test_ids)]\n",
        "    \n",
        "    folds.append(fold)\n",
        "print(folds)\n",
        "\n",
        "print(folds[1])\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSpry2AVHMsw"
      },
      "outputs": [],
      "source": [
        "train = [folds[i][0] for i in range(len(folds))] \n",
        "valid = [folds[i][1] for i in range(len(folds))] \n",
        "test = [folds[i][2] for i in range(len(folds))] \n",
        "     \n",
        "# dictionary of lists  \n",
        "dict = {'train': train, 'valid': valid, 'test': test}  \n",
        "       \n",
        "cv = pd.DataFrame(dict) \n",
        "    \n",
        "# saving the dataframe \n",
        "if not os.path.exists('/content/gdrive/MyDrive/Dataset/folds.csv'):\n",
        "  cv.to_csv('/content/gdrive/MyDrive/Dataset/folds.csv') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gidfROs6JlB6"
      },
      "outputs": [],
      "source": [
        "'''df=pd.read_csv('/content/gdrive/MyDrive/Dataset/folds.csv')\n",
        "train=df['train']\n",
        "train_ids = train.to_list()\n",
        "score1 = s1.to_dict(orient = 'list')\n",
        "score2 = s2.to_dict(orient = 'list')\n",
        "score3 = s3.to_dict(orient = 'list')\n",
        "train_ids[0].split()'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnbvey39uV2D"
      },
      "outputs": [],
      "source": [
        "folds=[\n",
        "    [[1017, 1050, 1069, 1045, 1051, 1066, 1052],[1048, 1051, 1052],[1067]], [[1017, 1050, 1069, 1045, 1051, 1066, 1052],[1067, 1047, 1068],[1048]],\n",
        "\n",
        "    ]\n",
        "fold_num=1\n",
        "train_ids, valid_ids,test_ids = folds[fold_num][0],folds[fold_num][1],folds[fold_num][2]\n",
        "train_df,  valid_df ,test_df = df[df.patient_id.isin(train_ids)],df[df.patient_id.isin(valid_ids)], df[df.patient_id.isin(test_ids)]\n",
        "'''\n",
        "print(\"\\nTRAIN DATA\\n\", train_df.shape)\n",
        "print(\"\\nVALID DATA\\n\", valid_df.shape)\n",
        "print(\"\\nTEST DATA\\n\", test_df.shape)\n",
        "'''\n",
        "D=[train_df,valid_df,test_df]\n",
        "for d in D:\n",
        "  d['video'] ='convex_' +d['patient_id'].astype(str) + '_' + d['analysis_id'].astype(str)+ '_' + d['file_area_code'].astype(str)\n",
        "\n",
        "  d=d[['video','rating_operator']]\n",
        "  d=d.reset_index(drop=True)\n",
        "\n",
        "\n",
        "train = train_df.to_dict(orient = 'list')\n",
        "valid = valid_df.to_dict(orient = 'list')\n",
        "test = test_df.to_dict(orient = 'list')\n",
        "train=train['video']\n",
        "valid=valid['video']\n",
        "test=test['video']\n",
        "cv=pd.DataFrame(test) \n",
        "if not os.path.exists('/content/gdrive/MyDrive/Dataset/test.csv'):\n",
        "  cv.to_csv('/content/gdrive/MyDrive/Dataset/test.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pyg_J9-dYbxV"
      },
      "source": [
        "## split the folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWW8GziQwkew"
      },
      "outputs": [],
      "source": [
        "root_dir = '/content/gdrive/MyDrive/Dataset/data/'\n",
        "videos_path='/content/gdrive/MyDrive/Dataset/frames'\n",
        "l=['train','valid','test']\n",
        "L=[train,valid,test]\n",
        "j=0\n",
        "for i in l:\n",
        "  if not os.path.exists(os.path.join(root_dir, i)):\n",
        "            os.mkdir(path=os.path.join(root_dir, i))\n",
        "\n",
        "\n",
        "\n",
        "for List in L:\n",
        "  path=os.path.join(root_dir, l[j])\n",
        "  video_files=[]\n",
        "  files = [os.path.join(videos_path,f) for f in os.listdir(videos_path) ]\n",
        "  for f in files:\n",
        "    for v in os.listdir(f):\n",
        "      if os.path.isfile(os.path.join(f,v)):\n",
        "       video_file=os.path.join(f,v)\n",
        "       video_files.append(video_file)\n",
        "       \n",
        "        \n",
        "        \n",
        "      if v.split('.')[0] in List :\n",
        "       \n",
        "\n",
        "        if not os.path.exists(os.path.join(path, v)):\n",
        "            \n",
        "            #os.mkdir(path=os.path.join(path, v))\n",
        "            shutil.copy(video_file, os.path.join(path, v))\n",
        "  j+=1\n",
        "\n",
        "\n",
        "\n",
        "print(count_files('/content/gdrive/MyDrive/Dataset/data/train')+count_files('/content/gdrive/MyDrive/Dataset/data/valid')+count_files('/content/gdrive/MyDrive/Dataset/data/test'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOEBvJeXYuKs"
      },
      "source": [
        "## organize the data by score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgHgWxoSNSkW"
      },
      "outputs": [],
      "source": [
        "score_folder(train,'train')\n",
        "score_folder(valid,'valid')\n",
        "score_folder(test,'test')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJGTcVzTTQGY"
      },
      "source": [
        "## test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxEeTYoyNzWN"
      },
      "outputs": [],
      "source": [
        "file_path1='/content/gdrive/MyDrive/Dataset/data/test/score0/convex_1048_1126_12.mat'\n",
        "file_path2='/content/gdrive/MyDrive/Dataset/data/test/score2/convex_1048_1124_10.mat'\n",
        "f1 = loadmat(file_path1)\n",
        "f2 = loadmat(file_path2)\n",
        "#f1= cv2.imread(file_path1)\n",
        "#f2= cv2.imread(file_path2)\n",
        "frames1=f1['frames']\n",
        "frames2=f2['frames']\n",
        "print(frames1.shape)\n",
        "print(frames2.shape)\n",
        "print(frames1.all()==frames2.all())\n",
        "Max1=np.max(frames1,axis=3)\n",
        "Max2=np.max(frames2,axis=3)\n",
        "#Min=np.min(frames1,axis=3)\n",
        "plt.imshow(Max1)\n",
        "print(Max1.size)\n",
        "plt.show()\n",
        "plt.imshow(Max2)\n",
        "print(Max2.shape)\n",
        "plt.show()\n",
        "\n",
        "#plt.imshow(Min)\n",
        "#print(Min.shape)\n",
        "#plt.show()\n",
        "\n",
        "'''m=np.concatenate((f1, f2), axis=2)\n",
        "plt.imshow(m)\n",
        "print(m.shape)\n",
        "plt.show()'''\n",
        "ii = cv2.imread(\"/content/gdrive/MyDrive/Dataset/data/test/score0/convex_1048_1126_8.jpg\")\n",
        "gray_image = cv2.cvtColor(ii, cv2.COLOR_BGR2GRAY)\n",
        "print(gray_image.shape)\n",
        "plt.imshow(gray_image)\n",
        "plt.show()\n",
        "y = np.expand_dims(gray_image, axis=-1)\n",
        "print(y.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhTDfec6Y9rx"
      },
      "source": [
        "## generate the min-max frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9melguKX1-H"
      },
      "outputs": [],
      "source": [
        "train_path='/content/gdrive/MyDrive/Dataset/data/train'\n",
        "valid_path='/content/gdrive/MyDrive/Dataset/data/valid'\n",
        "test_path='/content/gdrive/MyDrive/Dataset/data/test'\n",
        "path=[train_path,valid_path,test_path]\n",
        "\n",
        "for p in path:\n",
        "  files = [os.path.join(p,f) for f in os.listdir(p) if not os.path.isfile(os.path.join(p,f))]\n",
        "  \n",
        "  for f in files:\n",
        "    for v in os.listdir(f):\n",
        "      if os.path.isfile(os.path.join(f,v)):\n",
        "        file=os.path.join(f,v)\n",
        "        \n",
        "        matrix_max_min_frame_generator(file) \n",
        "        print('_____________________________________________next file___________________________________________________________')\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwLEkh3s7CTY"
      },
      "source": [
        "### coupling the min and max images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUNX8Jz8Bm5Q"
      },
      "outputs": [],
      "source": [
        "def im_concat(image): \n",
        "    \n",
        "    filename=image[0].split('/')[-1]\n",
        "    filename=filename.split('-')[0]\n",
        "    \n",
        "    filename1, _ = os.path.splitext(image[0])\n",
        "    filename1=os.path.dirname(filename1)\n",
        "    filename1=os.path.dirname(filename1)\n",
        "    print(filename1)\n",
        "    img1 = cv2.imread(image[0])\n",
        "    img2 = cv2.imread(image[1])\n",
        "    im_h = cv2.hconcat([img1, img2])\n",
        "    #print(image)\n",
        "    # show the output image\n",
        "    print(os.path.join(filename1,f\"{filename}.jpg\"))\n",
        "    if not os.path.exists(os.path.join(filename1,f\"{filename}.jpg\")):\n",
        "      plt.imshow(im_h)\n",
        "      plt.show()\n",
        "      cv2.imwrite(os.path.join(filename1,f\"{filename}.jpg\"), im_h)\n",
        "      print(os.path.join(filename1,f\"{filename}.jpg\"))\n",
        "    \n",
        "#x=['/content/gdrive/MyDrive/Dataset/data/test/score3/convex_1066_1151_1-MAXMIN/convex_1066_1151_1-Max.jpg','/content/gdrive/MyDrive/Dataset/data/test/score3/convex_1066_1151_1-MAXMIN/convex_1066_1151_1-Min.jpg']\n",
        "#im_concat(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBhRso-e7BB4"
      },
      "outputs": [],
      "source": [
        "train_path='/content/gdrive/MyDrive/Dataset/data/train'\n",
        "valid_path='/content/gdrive/MyDrive/Dataset/data/valid'\n",
        "test_path='/content/gdrive/MyDrive/Dataset/data/test'\n",
        "path=[train_path,valid_path,test_path]\n",
        "for p in path:\n",
        "  files = [os.path.join(p,f) for f in os.listdir(p) if not os.path.isfile(os.path.join(p,f))]\n",
        "  \n",
        "  for f in files:\n",
        "    for v in os.listdir(f):\n",
        "      if not  os.path.isfile(os.path.join(f,v)):\n",
        "        file=os.path.join(f,v)\n",
        "        images=[]\n",
        "        if count_files(file)<1:\n",
        "          print('this folder is empty',file)\n",
        "        if count_files(file)>1:\n",
        "          for j in os.listdir(file):\n",
        "            img=os.path.join(file,j)\n",
        "          \n",
        "            images.append(img)\n",
        "        \n",
        "          im_concat(images)\n",
        "          images=images[:2]\n",
        "          for i in images:\n",
        "            os.remove(i)\n",
        "            print(i,' removed')\n",
        "        \n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBQKlBIoGZ7X"
      },
      "outputs": [],
      "source": [
        "for p in path:\n",
        "  files = [os.path.join(p,f) for f in os.listdir(p) if not os.path.isfile(os.path.join(p,f))]\n",
        "  \n",
        "  for f in files:\n",
        "    for v in os.listdir(f):\n",
        "      if not  os.path.isfile(os.path.join(f,v)):\n",
        "        file=os.path.join(f,v)\n",
        "        images=[]\n",
        "        if count_files(file)<1:\n",
        "           print('this folder is empty',file)\n",
        "           shutil.rmtree(file)\n",
        "        if count_files(file)==1:\n",
        "           img=os.path.join(file,os.listdir(file)[0])\n",
        "           img_1=os.path.dirname(img)\n",
        "           rt=os.path.dirname(img_1)\n",
        "           shutil.move(img,rt)\n",
        "           shutil.rmtree(img_1)\n",
        "           print(img_1,'rmvd')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7lUNsnsgwdq"
      },
      "source": [
        "# other format dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQyWb9hpg3DX"
      },
      "outputs": [],
      "source": [
        "source_dir = r\"/content/gdrive/MyDrive/Dataset/data1\"\n",
        "destination_dir = r\"/content/gdrive/MyDrive/Dataset/data3\"\n",
        "#create a copy of the dataset\n",
        "shutil.copytree(source_dir, destination_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02lLUilPFgOJ"
      },
      "outputs": [],
      "source": [
        "path='/content/gdrive/MyDrive/Dataset/data'\n",
        "for root, dirs, files in os.walk(path, topdown=False):\n",
        "   for v in files:\n",
        "     if v.split('.')[1]=='jpg':\n",
        "       p=os.path.join(root, v)\n",
        "       print(p,'removed')\n",
        "       os.remove(p)\n",
        "\n",
        "path1='/content/gdrive/MyDrive/Dataset/data1'\n",
        "for root, dirs, files in os.walk(path1, topdown=False):\n",
        "   for v in files:\n",
        "     if v.split('.')[1]=='tiff':\n",
        "       p=os.path.join(root, v)\n",
        "       print(p,'removed')\n",
        "       os.remove(p)\n",
        "       \n",
        "\n",
        "path2='/content/gdrive/MyDrive/Dataset/data2'\n",
        "for root, dirs, files in os.walk(path2, topdown=False):\n",
        "   for v in files:\n",
        "     if v.split('.')[1]=='mat':\n",
        "       p=os.path.join(root, v)\n",
        "       print(p,'removed')\n",
        "       os.remove(p)\n",
        "       \n",
        "\n",
        "path2='/content/gdrive/MyDrive/Dataset/data3'\n",
        "for root, dirs, files in os.walk(path2, topdown=False):\n",
        "   for v in files:\n",
        "     if v.split('.')[1]=='npy':\n",
        "       p=os.path.join(root, v)\n",
        "       print(p,'removed')\n",
        "       os.remove(p)\n",
        "       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqWilAo_I-6s"
      },
      "outputs": [],
      "source": [
        "train_path='/content/gdrive/MyDrive/Dataset/data1/train'\n",
        "valid_path='/content/gdrive/MyDrive/Dataset/data1/valid'\n",
        "test_path='/content/gdrive/MyDrive/Dataset/data1/test'\n",
        "path=[train_path,valid_path,test_path]\n",
        "\n",
        "for p in path:\n",
        "  files = [os.path.join(p,f) for f in os.listdir(p) if not os.path.isfile(os.path.join(p,f))]\n",
        "  \n",
        "  for f in files:\n",
        "    for v in os.listdir(f):\n",
        "      if os.path.isfile(os.path.join(f,v)):\n",
        "        file=os.path.join(f,v)\n",
        "        \n",
        "        matrix_max_min_frame_generator(file) \n",
        "        print('_____________________________________________next file___________________________________________________________')\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHqHY1Oc9DpG"
      },
      "source": [
        "## numpy files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8t09qMsJXD2"
      },
      "outputs": [],
      "source": [
        "def im_concat_channels(image): \n",
        "    \n",
        "    filename=image[0].split('/')[-1]\n",
        "    filename=filename.split('-')[0]\n",
        "    \n",
        "    filename1, _ = os.path.splitext(image[0])\n",
        "    filename1=os.path.dirname(filename1)\n",
        "    filename1=os.path.dirname(filename1)\n",
        "    print(filename1)\n",
        "    img1 = cv2.imread(image[0])\n",
        "    img2 = cv2.imread(image[1])\n",
        "    \n",
        "    imc=np.concatenate((img1, img2), axis=2)\n",
        "    #print(image)\n",
        "    # show the output image\n",
        "    print(os.path.join(filename1,f\"{filename}.jpg\"))\n",
        "    if not os.path.exists(os.path.join(filename1,f\"{filename}.jpg\")):\n",
        "      #plt.imshow(imc)\n",
        "      #plt.show()\n",
        "      np.save(os.path.join(filename1,f\"{filename}.npy\"), imc)\n",
        "      print(os.path.join(filename1,f\"{filename}.npy\"))\n",
        "     \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZuE24O2KcHV"
      },
      "outputs": [],
      "source": [
        "train_path='/content/gdrive/MyDrive/Dataset/data/train'\n",
        "valid_path='/content/gdrive/MyDrive/Dataset/data/valid'\n",
        "test_path='/content/gdrive/MyDrive/Dataset/data/test'\n",
        "path=[train_path,valid_path,test_path]\n",
        "for p in path:\n",
        "  files = [os.path.join(p,f) for f in os.listdir(p) if not os.path.isfile(os.path.join(p,f))]\n",
        "  \n",
        "  for f in files:\n",
        "    for v in os.listdir(f):\n",
        "      if not  os.path.isfile(os.path.join(f,v)):\n",
        "        file=os.path.join(f,v)\n",
        "        images=[]\n",
        "        if count_files(file)<1:\n",
        "          print('this folder is empty',file)\n",
        "        if count_files(file)>1:\n",
        "          for j in os.listdir(file):\n",
        "            img=os.path.join(file,j)\n",
        "          \n",
        "            images.append(img)\n",
        "        \n",
        "          im_concat_channels(images)\n",
        "          images=images[:2]\n",
        "          for i in images:\n",
        "            os.remove(i)\n",
        "            print(i,' removed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cn4AdyP9PSZr"
      },
      "outputs": [],
      "source": [
        "for p in path:\n",
        "  files = [os.path.join(p,f) for f in os.listdir(p) if not os.path.isfile(os.path.join(p,f))]\n",
        "  \n",
        "  for f in files:\n",
        "    for v in os.listdir(f):\n",
        "      if not  os.path.isfile(os.path.join(f,v)):\n",
        "        file=os.path.join(f,v)\n",
        "        images=[]\n",
        "        if count_files(file)==1:\n",
        "           img=os.path.join(file,os.listdir(file)[0])\n",
        "           img_1=os.path.dirname(img)\n",
        "           rt=os.path.dirname(img_1)\n",
        "           shutil.move(img,rt)\n",
        "           shutil.rmtree(img_1)\n",
        "           print(img_1,'rmvd')\n",
        "        if count_files(file)<1:\n",
        "           print('this folder is empty',file)\n",
        "           shutil.rmtree(file)\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsHITfyS8w4h"
      },
      "source": [
        "## tif files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p15xnfmcUsXA"
      },
      "outputs": [],
      "source": [
        "path1='/content/gdrive/MyDrive/Dataset/data1'\n",
        "import tifffile\n",
        "for root, dirs, files in os.walk(path1, topdown=False):\n",
        "   for v in files:\n",
        "     \n",
        "      p=os.path.join(root, v)\n",
        "      filename=p.split('/')[-1]\n",
        "      filename=filename.split('-')[0]\n",
        "      filename=filename.split('.')[0]\n",
        "      filename1, _ = os.path.splitext(p)\n",
        "      filename1=os.path.dirname(filename1)\n",
        "      #filename1=os.path.dirname(filename1)\n",
        "      '''print(filename1)\n",
        "      print(filename)'''\n",
        "      \n",
        "      \n",
        "      \n",
        "      if not os.path.exists(os.path.join(filename1,f\"{filename}.tiff\")):\n",
        "      #plt.imshow(imc)\n",
        "      #plt.show()\n",
        "        if v.split('.')[1]=='npy':\n",
        "          im=np.load(p)\n",
        "          tifffile.imwrite(os.path.join(filename1,f\"{filename}.tiff\"),im)\n",
        "          print(os.path.join(filename1,f\"{filename}.tiff\"))\n",
        "      \n",
        "      \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOoJLIjMpYiw"
      },
      "outputs": [],
      "source": [
        "p='/content/gdrive/MyDrive/Dataset/data2/test/score0/convex_1048_1126_12.jpg'\n",
        "\n",
        "print(os.path.dirname(p).split('/')[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxIPXKOzZMId"
      },
      "outputs": [],
      "source": [
        "p='/content/gdrive/MyDrive/Dataset/data1/train/score0/convex_1045_1119_12.npy'\n",
        "a=np.load(p)\n",
        "print(a.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si1FcgXx-tq1"
      },
      "source": [
        "## resize files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWFhw-bm8tho"
      },
      "outputs": [],
      "source": [
        "p='/content/gdrive/MyDrive/Dataset/data1'\n",
        "datafiles=[]\n",
        "wrong=[]\n",
        "for root, dirs, files in os.walk(p, topdown=False):\n",
        "    for v in files: \n",
        "      if v.split('.')[1]=='npy':    \n",
        "          p=os.path.join(root, v)\n",
        "          datafiles.append(p)\n",
        "for file in datafiles:\n",
        "      img=np.load(file)\n",
        "      if img.shape != (688, 880, 6):\n",
        "        wrong.append(file)\n",
        "        #np.reshape(img,(688, 880,6))\n",
        "        a=img[:688,:880,::]\n",
        "        os.remove(file)\n",
        "        np.save(file, a)\n",
        "        print(file,'saved')\n",
        "        print(img.shape)\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiEf-gRlBwUS"
      },
      "outputs": [],
      "source": [
        "wrong\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eyjczrO8tSi"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0a9BbLFtbKt"
      },
      "source": [
        "# Frame-level Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPOYIiOXthFl"
      },
      "outputs": [],
      "source": [
        "path='/content/drive/MyDrive/Dati San Matteo Dataset 2'\n",
        "frame_score_path='/content/drive/MyDrive/Dataset/frames_score'\n",
        "for root, dirs, files in os.walk(path, topdown=False):\n",
        "   for v in files:\n",
        "     if v.split('_')[-1]=='score.mat':\n",
        "       p=os.path.join(root, v)\n",
        "       n=os.path.join(frame_score_path, v)\n",
        "       if not os.path.exists(n):\n",
        "          shutil.copy(p, frame_score_path)\n",
        "          print('file',p ,'added to',frame_score_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F51U5dqPThpp"
      },
      "source": [
        "## test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t07KhS0X00B3"
      },
      "outputs": [],
      "source": [
        "file_path1='/content/drive/MyDrive/Dataset/frames_score/convex_1017_1047_10_score.mat'\n",
        "file_path2='/content/drive/MyDrive/Dataset/frames_score/convex_1069_1156_12_score.mat'\n",
        "f1 = loadmat(file_path1)\n",
        "f2 = loadmat(file_path2)\n",
        "\n",
        "frames1=f1['Score_matrix']\n",
        "frames2=f2['Score_matrix']\n",
        "print(frames1.shape)\n",
        "print(frames2.shape)\n",
        "print(frames2.sum(0))\n",
        "\n",
        "\n",
        "#plt.imshow(Min)\n",
        "#print(Min.shape)\n",
        "#plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOzjKm5eTnZO"
      },
      "source": [
        "## label frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXn0R5pX5WBM"
      },
      "outputs": [],
      "source": [
        "\n",
        "frame_path='/content/drive/MyDrive/Dataset/frames'\n",
        "frame_score_path='/content/drive/MyDrive/Dataset/frames_score'\n",
        "frames_data='/content/drive/MyDrive/Dataset/frames_dataset'\n",
        "frame_scores = [] \n",
        "\n",
        "if not os.path.exists(frames_data):\n",
        "    # Create the folder\n",
        "    os.makedirs(frames_data)\n",
        "\n",
        "def iterate_elements(x):\n",
        "    \n",
        "    return x\n",
        "    \n",
        "def action_0(score,file,frame,i):\n",
        "    if not os.path.exists(frames_data+'/'+file.split('.')[0]+'_frame{}_'.format(i)+str(score)+'.jpg'):\n",
        "      cv2.imwrite(frames_data+'/'+file.split('.')[0]+'_frame{}_'.format(i)+str(score)+'.jpg', frame)\n",
        "      print(frames_data+'/'+file.split('.')[0]+'_frame{}_'.format(i)+str(score)+'.jpg', 'is saved')\n",
        "def action_1(score,file,frame,i):\n",
        "    if not os.path.exists(frames_data+'/'+file.split('.')[0]+'_frame{}_'.format(i)+str(score)+'.jpg'):\n",
        "      cv2.imwrite(frames_data+'/'+file.split('.')[0]+'_frame{}_'.format(i)+str(score)+'.jpg', frame)\n",
        "      print(frames_data+'/'+file.split('.')[0]+'_frame{}_'.format(i)+str(score)+'.jpg', 'is saved')\n",
        "def action_2(score,file,frame,i):\n",
        "    if not os.path.exists(frames_data+'/'+file.split('.')[0]+'_frame{}_'.format(i)+str(score)+'.jpg'):\n",
        "      cv2.imwrite(frames_data+'/'+file.split('.')[0]+'_frame{}_'.format(i)+str(score)+'.jpg', frame)\n",
        "      print(frames_data+'/'+file.split('.')[0]+'_frame{}_'.format(i)+str(score)+'.jpg', 'is saved')\n",
        "def action_3(score,file,frame,i):\n",
        "   if not os.path.exists(frames_data+'/'+file.split('.')[0]+'_frame{}_'.format(i)+str(score)+'.jpg'):\n",
        "      cv2.imwrite(frames_data+'/'+file.split('.')[0]+'_frame{}_'.format(i)+str(score)+'.jpg', frame)\n",
        "      print(frames_data+'/'+file.split('.')[0]+'_frame{}_'.format(i)+str(score)+'.jpg', 'is saved')\n",
        "actions = {\n",
        "    0: action_0,\n",
        "    1: action_1,\n",
        "    2: action_2,\n",
        "    3: action_3,\n",
        "}\n",
        "\n",
        "for root, dirs, files in os.walk(frame_path, topdown=False):\n",
        "  for root1, dirs1, files1 in os.walk(frame_score_path, topdown=False):\n",
        "   \n",
        "   for v in files:\n",
        "     \n",
        "     for s in files1:\n",
        "       \n",
        "       if (s.split('_')[:4]==v.split('.')[0].split('_')):\n",
        "         #print('true')\n",
        "         p=os.path.join(root1, s)\n",
        "         sf = loadmat(p)\n",
        "         f=loadmat(os.path.join(root, v))\n",
        "         score=sf['Score_matrix']\n",
        "         frames=f['frames']\n",
        "         scores=score.sum(0)\n",
        "         #print(len(scores))\n",
        "         #print(frames.shape)\n",
        "         FF=[]\n",
        "         for i in range(frames.shape[-1]):\n",
        "           frame=frames[:,:,:,i]\n",
        "           FF.append(frame)\n",
        "         #np.expand_dims(np.apply_along_axis(iterate_elements, axis=-1,arr=frames),axis=-1))\n",
        "         for i,(score,frame) in enumerate(zip(scores,FF)):\n",
        "        \n",
        "           #frame_score= (score,frame)\n",
        "           #print(score)\n",
        "           #print(frame.shape)\n",
        "           if score in actions:\n",
        "              actions[score](score,v,frame,i)\n",
        "              \n",
        "           else:\n",
        "             print('error')\n",
        "             break\n",
        "         \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gj3mYKKid9LN"
      },
      "outputs": [],
      "source": [
        "frames_data='/content/drive/MyDrive/Dataset/frames_dataset'\n",
        "count_files(frames_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDmjPiJdJEgu"
      },
      "outputs": [],
      "source": [
        "#shutil.rmtree(frames_data, ignore_errors=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlFxVvR-xkNX"
      },
      "outputs": [],
      "source": [
        " frames_data='/content/drive/MyDrive/Dataset/frames_dataset/train'\n",
        " all_frames=[]\n",
        " for v in  os.listdir(frames_data) :\n",
        "   if os.path.isfile(os.path.join(frames_data, v)):\n",
        "    all_frames.append(os.path.join(frames_data, v))\n",
        "    \n",
        "X=[]\n",
        "\n",
        "for frame_path in  all_frames:\n",
        "       \n",
        "      file=  frame_path.split('/')[-1]\n",
        "      f=file.split('.')[0]\n",
        "      \n",
        "      patient=f.split('_')[1]\n",
        "      #print(patient)\n",
        "      X.append(patient)\n",
        "set(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRlGpKLyLf4j"
      },
      "outputs": [],
      "source": [
        "l=['train','valid','test']\n",
        "frames_data='/content/gdrive/MyDrive/Dataset/frames_dataset'\n",
        "\n",
        "for i in l:\n",
        "  #shutil.rmtree(os.path.join(frames_data, i), ignore_errors=True)\n",
        "  #print(os.path.join(frames_data, i)+' deleted')\n",
        "  if not os.path.exists(os.path.join(frames_data, i)):\n",
        "    os.mkdir(path=os.path.join(frames_data, i))\n",
        "    print(os.path.join(frames_data, i)+' is created')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo14Bv3eFENd"
      },
      "source": [
        "## split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDf_p2OyFDCH"
      },
      "outputs": [],
      "source": [
        "#shutil.copytree('/content/drive/MyDrive/Dataset/frames_dataset/train','/content/drive/MyDrive/Dataset/frame_level_dataset/train')\n",
        "#shutil.copytree('/content/drive/MyDrive/Dataset/frames_dataset/valid','/content/drive/MyDrive/Dataset/frame_level_dataset/train')\n",
        "#shutil.copytree('/content/drive/MyDrive/Dataset/frames_dataset/test','/content/drive/MyDrive/Dataset/frame_level_dataset/train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VV81fDRFsYpW"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "folds=[\n",
        "    [[1047, 1066, 1017, 1069, 1068, 1045, 1050],[1048, 1051, 1052],[1067]], [[1017, 1050, 1069, 1045, 1051, 1066, 1052],[1067, 1047, 1068],[1048]],\n",
        "\n",
        "    ]\n",
        "\n",
        "fold_num=0\n",
        "train,valid,test = folds[fold_num][0],folds[fold_num][1],folds[fold_num][2]\n",
        "\n",
        "l=['train','valid','test']\n",
        "L=[train,valid,test]\n",
        "frames_data=\"/content/drive/MyDrive/Dataset/frames_dataset\"\n",
        "#dataset_path='/content/drive/MyDrive/Dataset/frame_level_dataset/'\n",
        "\n",
        "\n",
        "\n",
        "j=0\n",
        "for List in L:\n",
        "  \n",
        "  #print(List)\n",
        "  #path=os.path.join(dataset_path, l[j])\n",
        "  path=os.path.join(frames_data, l[j])\n",
        "  \n",
        "\n",
        "  for f in  os.listdir(frames_data) :\n",
        "   \n",
        "   if os.path.isfile(frame_path): \n",
        "    #for frame_path in  all_frames:\n",
        "        frame_path=os.path.join(frames_data,f)\n",
        "        file=  frame_path.split('/')[-1]\n",
        "        f=f.split('.')[0]\n",
        "        \n",
        "        patient=f.split('_')[1] \n",
        "        \n",
        "        if patient in str(List) :\n",
        "          #print(List,path)\n",
        "          new_path=os.path.join(path, file)\n",
        "          if not os.path.exists(new_path):\n",
        "              \n",
        "              #os.mkdir(path=os.path.join(path, v))\n",
        "              shutil.copy(frame_path,new_path)\n",
        "              print(frame_path,new_path)\n",
        "        else:\n",
        "          continue\n",
        "  j+=1\n",
        "\n",
        "\n",
        "\n",
        "#print(count_files('/content/gdrive/MyDrive/Dataset/data/train')+count_files('/content/gdrive/MyDrive/Dataset/data/valid')+count_files('/content/gdrive/MyDrive/Dataset/data/test'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8v-L9R_oGlWs"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "print('train: ', count_files('/content/gdrive/MyDrive/Dataset/frames_dataset/train'))\n",
        "print('valid: ',count_files('/content/gdrive/MyDrive/Dataset/frames_dataset/valid'))\n",
        "print('test: ',count_files('/content/gdrive/MyDrive/Dataset/frames_dataset/test'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-QTo-iIepeP"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "folder_path=\"/content/drive/MyDrive/Dataset/frames_dataset\"\n",
        "#files = [f for f in os.listdir(folder_path) if  os.path.isfile(os.path.join(folder_path, f))]\n",
        "for f in  os.listdir(folder_path) :\n",
        "   print(f)\n",
        "   if os.path.isfile(os.path.join(folder_path, f)):\n",
        "\n",
        "      os.remove(os.path.join(folder_path, f))\n",
        "      print(os.path.join(folder_path, f))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbXolkLGF0zy"
      },
      "outputs": [],
      "source": [
        "root_dir = '/content/drive/MyDrive/Dataset/frames_dataset/'\n",
        "S=['train','valid','test']\n",
        "for s in S: \n",
        "  path0=root_dir+s+'/score0'\n",
        "  path1=root_dir+s+'/score1'\n",
        "  path2=root_dir+s+'/score2'\n",
        "  path3=root_dir+s+'/score3'\n",
        "  path=[path0,path1,path2,path3]\n",
        "  frames_path=root_dir+s\n",
        "  for i in path:\n",
        "    if not os.path.exists(i):\n",
        "          os.mkdir(i)\n",
        "  \n",
        "  files = [f for f in os.listdir(frames_path)]\n",
        "  #print(files)\n",
        "  for v in files:\n",
        "    \n",
        "      #print(v.split('.')[0].split('_')[-1])\n",
        "      if os.path.isfile(os.path.join(frames_path,v)):\n",
        "        \n",
        "        \n",
        "        \n",
        "        if v.split('.')[0].split('_')[-1] == '0' :\n",
        "       \n",
        "\n",
        "            if not os.path.exists(os.path.join(path0, v)):\n",
        "              print(os.path.join(path0, v))\n",
        "              #os.mkdir(path=os.path.join(path, v))\n",
        "              shutil.move(os.path.join(frames_path,v), os.path.join(path0, v))\n",
        "\n",
        "        elif v.split('.')[0].split('_')[-1] == '1' :\n",
        "       \n",
        "\n",
        "            if not os.path.exists(os.path.join(path1, v)):\n",
        "              \n",
        "              print(os.path.join(path1, v))\n",
        "              #os.mkdir(path=os.path.join(path, v))\n",
        "              shutil.move(os.path.join(frames_path,v), os.path.join(path1, v))\n",
        "\n",
        "        elif v.split('.')[0].split('_')[-1] == '2' :\n",
        "       \n",
        "\n",
        "            if not os.path.exists(os.path.join(path2, v)):\n",
        "              \n",
        "              print(os.path.join(path2, v))\n",
        "              #os.mkdir(path=os.path.join(path, v))\n",
        "              shutil.move(os.path.join(frames_path,v), os.path.join(path2, v))\n",
        "   \n",
        "        elif v.split('.')[0].split('_')[-1] == '3' :\n",
        "       \n",
        "\n",
        "            if not os.path.exists(os.path.join(path3, v)):\n",
        "              \n",
        "              print(os.path.join(path3, v))\n",
        "              #os.mkdir(path=os.path.join(path, v))\n",
        "              shutil.move(os.path.join(frames_path,v), os.path.join(path3, v))\n",
        "              #copy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Max-Min dataset\n"
      ],
      "metadata": {
        "id": "vnYoXtDIPM1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path=r\"/content/drive/MyDrive/Dataset/data2\"\n",
        "new_path=r\"/content/drive/MyDrive/Dataset/max-min-avg_data\"\n",
        "\n",
        "for root, dirs, files in os.walk(data_path, topdown=False):\n",
        "   for v in files:\n",
        "     \n",
        "     p=os.path.join(root, v)\n",
        "     #print(p)\n",
        "     filename=p.split('/')[-1]\n",
        "     filename=filename.split('-')[0]\n",
        "     filename=filename.split('.')[0]\n",
        "     filename1, _ = os.path.splitext(p)\n",
        "     #print(filename1)\n",
        "     filename1=os.path.dirname(filename1)\n",
        "     filename1=filename1.split('/')[-2:]\n",
        "     \n",
        "     filename1='/'.join(filename1)\n",
        "     np=os.path.join(new_path,filename1)\n",
        "     if not os.path.exists(np):\n",
        "        os.makedirs(np)\n",
        "        print(np)\n",
        "     #print(filename)\n",
        "\n",
        "     img = cv2.imread(p)\n",
        "  \n",
        "     # cv2.imread() -> takes an image as an input\n",
        "     h, w, channels = img.shape\n",
        "        \n",
        "     half = w//2\n",
        "        \n",
        "      \n",
        "     Max = img[:, :half] \n",
        "        \n",
        " \n",
        "     Min = img[:, half:]  \n",
        "        \n",
        "     \n",
        "     ''' plt.imshow(Max)\n",
        "     plt.show()\n",
        "     plt.imshow(Min)\n",
        "     plt.show()'''\n",
        "      \n",
        "     if not os.path.exists(os.path.join(np,f\"{filename}-Max.jpg\")) :\n",
        "        cv2.imwrite(os.path.join(np,f\"{filename}-Max.jpg\"), Max)\n",
        "        print(os.path.join(np,f\"{filename}-Max.jpg\"), 'saved')\n",
        "     if not os.path.exists(os.path.join(np,f\"{filename}-Min.jpg\")) :\n",
        "        cv2.imwrite(os.path.join(np,f\"{filename}-Min.jpg\"), Min)\n",
        "        print(os.path.join(np,f\"{filename}-Min.jpg\"), 'saved')\n",
        "     "
      ],
      "metadata": {
        "id": "SiFa2Lh3PUfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c=0\n",
        "for root, dirs, files in os.walk(new_path, topdown=False):\n",
        "   for v in files:\n",
        "     c+=1\n",
        "print(c)"
      ],
      "metadata": {
        "id": "qM53PoP6PZQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path=r\"/content/drive/MyDrive/Dataset/man-mix-avg_data\"\n",
        "max_path=r\"/content/drive/MyDrive/Dataset/Max_data\"\n",
        "min_path=r\"/content/drive/MyDrive/Dataset/Min_data\"\n",
        "\n",
        "for root, dirs, files in os.walk(data_path, topdown=False):\n",
        "   for v in files:\n",
        "     \n",
        "     p=os.path.join(root, v)\n",
        "     #print(p)\n",
        "     filename=p.split('/')[-1]\n",
        "     #filename=filename.split('-')[0]\n",
        "     filename=filename.split('.')[0]\n",
        "     filename1, _ = os.path.splitext(p)\n",
        "     #print(filename)\n",
        "     filename1=os.path.dirname(filename1)\n",
        "     filename1=filename1.split('/')[-2:]\n",
        "     \n",
        "     filename1='/'.join(filename1)\n",
        "     np1=os.path.join(max_path,filename1)\n",
        "     np2=os.path.join(min_path,filename1)\n",
        "     if not os.path.exists(np1):\n",
        "        os.makedirs(np1)\n",
        "        print(np1)\n",
        "     if not os.path.exists(np2):\n",
        "        os.makedirs(np2)\n",
        "        print(np2)\n",
        "     if not os.path.exists(os.path.join(np1,f\"{filename}.jpg\")) :  \n",
        "      if filename.split('-')[-1]=='Max':\n",
        "        print(os.path.join(np1,f\"{filename}.jpg\"))\n",
        "        shutil.copy(p,os.path.join(np1,f\"{filename}.jpg\"))\n",
        "     if not os.path.exists(os.path.join(np2,f\"{filename}.jpg\")) : \n",
        "      if filename.split('-')[-1]=='Min':\n",
        "        print(os.path.join(np2,f\"{filename}.jpg\"))\n",
        "        shutil.copy(p,os.path.join(np2,f\"{filename}.jpg\"))\n",
        "\n",
        "     \n",
        "     ''' plt.imshow(Max)\n",
        "     plt.show()\n",
        "     plt.imshow(Min)\n",
        "     plt.show()'''\n",
        "      \n",
        "     ''' if not os.path.exists(os.path.join(np,f\"{filename}-Max.jpg\")) :\n",
        "        cv2.imwrite(os.path.join(np,f\"{filename}-Max.jpg\"), Max)\n",
        "        print(os.path.join(np,f\"{filename}-Max.jpg\"), 'saved')\n",
        "      if not os.path.exists(os.path.join(np,f\"{filename}-Min.jpg\")) :\n",
        "        cv2.imwrite(os.path.join(np,f\"{filename}-Min.jpg\"), Min)\n",
        "        print(os.path.join(np,f\"{filename}-Min.jpg\"), 'saved')'''"
      ],
      "metadata": {
        "id": "1MWjtyUyEqvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Max Min Average Dataset"
      ],
      "metadata": {
        "id": "WYqQHF0Iglrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_path='/content/gdrive/MyDrive/Dataset/max-min-avg_data'\n",
        "\n",
        "def matrix_avg_frame_generator(file_path):\n",
        "  \n",
        "  p=file_path\n",
        "  #print(p)\n",
        "  filename=p.split('/')[-1]\n",
        "  #filename=filename.split('-')[0]\n",
        "  filename=filename.split('.')[0]\n",
        "  filename1, _ = os.path.splitext(p)\n",
        "  #print(filename)\n",
        "  filename1=os.path.dirname(filename1)\n",
        "  filename1=filename1.split('/')[-2:]\n",
        "     \n",
        "  filename1='/'.join(filename1)\n",
        "  np1=os.path.join(avg_path,filename1)\n",
        "  #print(np1)\n",
        "  \n",
        " \n",
        "  \n",
        "  if not os.path.exists(os.path.join(np1,f\"{filename}-avg.jpg\")) :\n",
        "    f = loadmat(file_path)\n",
        "    frames=f['frames']\n",
        "    avg=np.mean(frames,axis=3)\n",
        "    #avg=np.array(avg)\n",
        "    '''plt.imshow(avg)\n",
        "    print(avg.shape)\n",
        "    plt.show()\n",
        "    print(type(avg))'''\n",
        "      \n",
        "    imageio.imwrite(os.path.join(np1,f\"{filename}-avg.jpg\"),avg)\n",
        "    print(os.path.join(np1,f\"{filename}-avg.jpg\"))\n",
        "\n",
        "\n",
        "'''p='/content/gdrive/MyDrive/Dataset/data/test/score0/convex_1048_1126_12.mat'\n",
        "matrix_avg_frame_generator(p)\n",
        "print(os.path.exists('/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score0/convex_1048_1126_12-avg.jpg'))\n",
        "img1 = cv2.imread('/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score0/convex_1048_1126_12-avg.jpg')\n",
        "#img1=np.array(img1)\n",
        "print(type(img1))\n",
        "plt.imshow(img1)\n",
        "\n",
        "plt.show()'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "xSIuaKaYiuw9",
        "outputId": "d0094e65-5673-4cc9-83b9-880cc5c45db2"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"p='/content/gdrive/MyDrive/Dataset/data/test/score0/convex_1048_1126_12.mat'\\nmatrix_avg_frame_generator(p)\\nprint(os.path.exists('/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score0/convex_1048_1126_12-avg.jpg'))\\nimg1 = cv2.imread('/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score0/convex_1048_1126_12-avg.jpg')\\n#img1=np.array(img1)\\nprint(type(img1))\\nplt.imshow(img1)\\n\\nplt.show()\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path='/content/gdrive/MyDrive/Dataset/data/train'\n",
        "valid_path='/content/gdrive/MyDrive/Dataset/data/valid'\n",
        "test_path='/content/gdrive/MyDrive/Dataset/data/test'\n",
        "path=[train_path,valid_path,test_path]\n",
        "\n",
        "for p in path:\n",
        "  files = [os.path.join(p,f) for f in os.listdir(p) if not os.path.isfile(os.path.join(p,f))]\n",
        "  \n",
        "  for f in files:\n",
        "    for v in os.listdir(f):\n",
        "      if os.path.isfile(os.path.join(f,v)):\n",
        "        file=os.path.join(f,v)\n",
        "        \n",
        "        matrix_avg_frame_generator(file) \n",
        "        #print('_____________________________________________next file___________________________________________________________')"
      ],
      "metadata": {
        "id": "7djH04nUm1sO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path='/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/'\n",
        "valid_path='/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/'\n",
        "test_path='/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/'\n",
        "path=[train_path,valid_path,test_path]\n",
        "scores=['score0','score1','score2','score3']\n",
        "def group_files(path):\n",
        "   \n",
        "    files = {}\n",
        "\n",
        "   \n",
        "    for file in os.listdir(path):\n",
        "      if os.path.isfile(os.path.join(os.path.join(path,file))):  \n",
        "        file_name = os.path.splitext(file)[0]\n",
        "        file_name= file_name.split('-')[0]\n",
        "        #print(file_name)\n",
        "        if file_name not in files:\n",
        "            files[file_name] = []\n",
        "\n",
        "        files[file_name].append(file)\n",
        "\n",
        "    for file_name, file_list in files.items():\n",
        "        #print(files.items())\n",
        "        folder_path = os.path.join(path, file_name) +'.'\n",
        "        \n",
        "        os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "        for file in file_list:\n",
        "            file_path = os.path.join(path, file)\n",
        "            print(file_path, folder_path)\n",
        "            shutil.move(file_path, folder_path)\n",
        "\n",
        "# Call the group_files function with the path to the directory\n",
        "# containing the files you want to group\n",
        "for p in path:\n",
        "  for s in scores:\n",
        "    group_files(p+s)"
      ],
      "metadata": {
        "id": "z6YFlF2Z4GHZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def im_concat_3channels(image): \n",
        "    img=[]\n",
        "    filename=image[0].split('/')[-1]\n",
        "    filename=filename.split('-')[0]\n",
        "    \n",
        "    filename1, _ = os.path.splitext(image[0])\n",
        "    filename1=os.path.dirname(filename1)\n",
        "    filename1=os.path.dirname(filename1)\n",
        "    #print(filename1)\n",
        "    for i in range(3):\n",
        "      im=cv2.imread(image[i])\n",
        "      # Convert the image from 3 channels to 1 channel\n",
        "      im = np.mean(im, axis=2)\n",
        "      \n",
        "      im = np.expand_dims(im, axis=-1)\n",
        "      #print(im.shape)\n",
        "      img.append(im)\n",
        "    \n",
        "\n",
        "\n",
        "    imc=np.concatenate((img[0], img[1],img[2]), axis=2)\n",
        "    '''plt.imshow(imc)\n",
        "    plt.show()'''\n",
        "    #print(image)\n",
        "    # show the output image\n",
        "    \n",
        "    if not os.path.exists(os.path.join(filename1,f\"{filename}-all.jpg\")):\n",
        "      \n",
        "      cv2.imwrite(os.path.join(filename1,f\"{filename}-all.jpg\"),imc)\n",
        "      print(os.path.join(filename1,f\"{filename}-all.jpg\"))\n",
        "      \n",
        "\n",
        "\n",
        "'''images=['/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score0/convex_1048_1126_12./convex_1048_1126_12-Max.jpg','/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score0/convex_1048_1126_12./convex_1048_1126_12-Min.jpg','/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score0/convex_1048_1126_12./convex_1048_1126_12-avg.jpg']\n",
        "im_concat_3channels(images)'''"
      ],
      "metadata": {
        "id": "gsu8o1_50ksL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "6332a166-3239-4df2-98ed-c799c1f312dd"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"images=['/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score0/convex_1048_1126_12./convex_1048_1126_12-Max.jpg','/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score0/convex_1048_1126_12./convex_1048_1126_12-Min.jpg','/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score0/convex_1048_1126_12./convex_1048_1126_12-avg.jpg']\\nim_concat_3channels(images)\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path='/content/gdrive/MyDrive/Dataset/max-min-avg_data/train'\n",
        "valid_path='/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid'\n",
        "test_path='/content/gdrive/MyDrive/Dataset/max-min-avg_data/test'\n",
        "path=[train_path,valid_path,test_path]\n",
        "for p in path:\n",
        "  files = [os.path.join(p,f) for f in os.listdir(p) if not os.path.isfile(os.path.join(p,f))]\n",
        "  \n",
        "  for f in files:\n",
        "    for v in os.listdir(f):\n",
        "      if not  os.path.isfile(os.path.join(f,v)):\n",
        "        file=os.path.join(f,v)\n",
        "        \n",
        "        images=[]\n",
        "        if count_files(file)<1:\n",
        "          print('this folder is empty',file)\n",
        "        if count_files(file)>1:\n",
        "          \n",
        "          for j in os.listdir(file):\n",
        "            img=os.path.join(file,j)\n",
        "            if img.split('.')[-1]!='jpg':\n",
        "              os.remove(img)\n",
        "            images.append(img)\n",
        "          \n",
        "          im_concat_3channels(images)\n",
        "          images=images[:3]\n",
        "          #print(len(images))"
      ],
      "metadata": {
        "id": "hjfGYT6s1Jnq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b74ee095-21d1-47fe-a30d-b0bc59b8e7ce"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1066_1151_12-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1066_1151_13-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1066_1151_14-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1069_1158_14-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1069_1156_1-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1069_1156_2-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1069_1156_13-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1069_1156_14-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1052_1129_13-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1052_1133_2-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1052_1133_3-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1052_1133_4-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1052_1133_5-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1052_1133_6-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1052_1133_9-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1052_1133_10-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1052_1133_12-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1052_1133_13-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1052_1133_14-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1045_1119_12-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1045_1119_13-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1045_1119_14-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1045_1119_3-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1045_1119_6-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1045_1120_1-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1045_1120_10-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1045_1120_11-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1045_1120_12-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1045_1120_13-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1045_1120_14-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1045_1120_2-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1045_1120_3-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1045_1120_5-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1045_1120_7-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1045_1120_8-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score0/convex_1045_1120_9-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1050_1127_11-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1051_1128_3-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1051_1128_4-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1051_1128_5-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1051_1128_6-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1051_1128_10-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1051_1128_12-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1069_1158_1-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1069_1158_2-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1069_1158_7-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1069_1158_10-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1069_1158_9-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1069_1158_11-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1069_1158_12-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1069_1158_13-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1052_1129_3-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1052_1129_5-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1052_1129_9-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1052_1129_10-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1052_1129_11-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1052_1129_12-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1052_1129_6-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1052_1129_14-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1052_1133_1-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1045_1119_2-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1045_1119_5-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1017_1047_13-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1017_1047_2-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1017_1047_4-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1017_1047_6-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1017_1048_12-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score1/convex_1017_1048_14-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1050_1127_5-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1050_1127_7-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1050_1127_8-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1050_1127_10-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1050_1127_12-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1050_1127_14-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1051_1128_8-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1051_1128_9-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1051_1128_13-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1051_1128_14-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1066_1151_9-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1066_1151_3-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1066_1151_10-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1069_1158_3-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1069_1158_4-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1069_1158_5-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1069_1158_6-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1069_1158_8-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1069_1156_3-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1069_1156_4-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1069_1156_6-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1069_1156_7-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1069_1156_8-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1069_1156_9-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1069_1156_10-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1069_1156_11-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1069_1156_12-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1069_1156_5-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1052_1129_1-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1052_1129_2-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1052_1129_4-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1052_1129_7-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1052_1133_7-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1052_1133_8-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1052_1133_11-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1045_1119_10-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1045_1119_11-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1045_1119_7-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1045_1119_4-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1045_1119_8-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1045_1119_9-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1045_1120_4-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1017_1047_1-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1017_1047_10-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1017_1047_11-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1017_1047_12-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1017_1047_14-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1017_1047_5-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1017_1047_7-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1017_1047_8-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1017_1047_9-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1017_1047_3-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1017_1048_10-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1017_1048_11-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1017_1048_13-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1017_1048_2-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1017_1048_3-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1017_1048_5-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1017_1048_6-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1017_1048_9-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score2/convex_1017_1048_1-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score3/convex_1050_1127_1-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score3/convex_1050_1127_2-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score3/convex_1050_1127_4-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score3/convex_1050_1127_9-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score3/convex_1050_1127_13-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score3/convex_1051_1128_1-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score3/convex_1051_1128_2-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score3/convex_1051_1128_7-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score3/convex_1051_1128_11-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score3/convex_1066_1151_1-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score3/convex_1066_1151_2-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score3/convex_1066_1151_4-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score3/convex_1066_1151_5-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score3/convex_1052_1129_8-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score3/convex_1045_1119_1-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score3/convex_1017_1048_4-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score3/convex_1017_1048_7-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/train/score3/convex_1017_1048_8-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score0/convex_1047_1122_13-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score0/convex_1047_1122_14-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score0/convex_1047_1122_8-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score1/convex_1068_1155_11-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score1/convex_1047_1122_10-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score1/convex_1068_1155_12-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score1/convex_1068_1155_13-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score1/convex_1068_1155_14-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score1/convex_1068_1157_5-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score1/convex_1068_1157_6-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score1/convex_1068_1157_14-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1047_1122_1-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1047_1122_12-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1047_1122_2-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1047_1122_3-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1047_1122_6-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1047_1122_7-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1047_1122_9-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1067_1152_9-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1067_1152_11-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1067_1152_12-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1067_1153_2-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1067_1153_5-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1067_1153_3-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1067_1153_7-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1067_1153_8-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1067_1153_10-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1067_1153_11-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1067_1153_12-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1067_1153_13-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1067_1153_14-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1068_1155_5-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1068_1155_3-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1068_1155_7-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1068_1155_8-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1068_1157_1-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1068_1157_3-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1068_1157_4-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1068_1157_7-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1068_1157_9-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1068_1157_11-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1068_1157_12-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score2/convex_1068_1157_13-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score3/convex_1047_1122_4-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score3/convex_1067_1152_1-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score3/convex_1047_1122_5-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score3/convex_1067_1152_2-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score3/convex_1067_1152_3-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score3/convex_1067_1152_4-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score3/convex_1067_1152_7-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score3/convex_1067_1152_8-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score3/convex_1067_1152_10-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score3/convex_1067_1152_13-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score3/convex_1067_1152_14-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score3/convex_1067_1152_6-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score3/convex_1067_1152_5-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score3/convex_1067_1153_4-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score3/convex_1067_1153_6-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score3/convex_1067_1153_9-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score3/convex_1067_1153_1-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score3/convex_1068_1155_1-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score3/convex_1068_1155_2-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score3/convex_1068_1155_4-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score3/convex_1068_1155_6-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score3/convex_1068_1155_9-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score3/convex_1068_1155_10-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score3/convex_1068_1157_2-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score3/convex_1068_1157_8-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/valid/score3/convex_1068_1157_10-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score0/convex_1048_1126_8-all.jpg\n",
            "this folder is empty /content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score0/.ipynb_checkpoints\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score1/convex_1048_1126_11-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score1/convex_1048_1126_13-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score1/convex_1048_1124_12-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score1/convex_1048_1126_14-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score1/convex_1048_1124_13-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score2/convex_1048_1126_10-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score2/convex_1048_1126_2-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score2/convex_1048_1126_3-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score2/convex_1048_1126_7-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score2/convex_1048_1124_10-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score2/convex_1048_1124_11-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score2/convex_1048_1124_14-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score2/convex_1048_1124_8-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score3/convex_1048_1126_1-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score3/convex_1048_1126_4-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score3/convex_1048_1126_5-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score3/convex_1048_1126_6-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score3/convex_1048_1126_9-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score3/convex_1048_1124_1-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score3/convex_1048_1124_3-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score3/convex_1048_1124_4-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score3/convex_1048_1124_6-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score3/convex_1048_1124_7-all.jpg\n",
            "/content/gdrive/MyDrive/Dataset/max-min-avg_data/test/score3/convex_1048_1124_9-all.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source_dir = r\"/content/gdrive/MyDrive/Dataset/max-min-avg_data\"\n",
        "destination_dir = r\"/content/gdrive/MyDrive/Dataset/3mixed\"\n",
        "#create a copy of the dataset\n",
        "shutil.copytree(source_dir, destination_dir)\n",
        "shutil.rmtree(source_dir, destination_dir)"
      ],
      "metadata": {
        "id": "r847Dz_jOvEZ",
        "outputId": "aa2b9482-ba4f-4969-fc9f-a32edd7a5054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/Dataset/3mixed'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sarsKR1Qesaz"
      },
      "source": [
        "# download the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zs3JwEvuexQu"
      },
      "outputs": [],
      "source": [
        "!zip -r '/content/drive/MyDrive/Dataset/frames_dataset.zip' '/content/drive/MyDrive/Dataset/frames_dataset'"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ta_oXqsDvsLh",
        "BBIie2TvwACQ",
        "ea1EbvAhvL-3",
        "on6VfOzTu83F",
        "ZMzoabySoyky",
        "I2owOzhPuQWX",
        "sVh7c3F-uZ52",
        "jeEMnOJIgjzX",
        "l7lUNsnsgwdq",
        "mHqHY1Oc9DpG",
        "CsHITfyS8w4h",
        "W0a9BbLFtbKt"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyN/UcG0QuzUYwEPZU9MgXq9",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}